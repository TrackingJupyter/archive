April 26, 2019

Tracking Jupyter Newsletter, the Sixteenth...
=============================================

by Tony Hirst

Welcome to this sixteenth edition of the _Tracking Jupyter_ newsletter (#TJ16).  
  
Two to the four issues, and all's well. Ish. There never seems to be less content, and only ever more ways of combining it... That said, if you host your blog on Medium, (and pretend it isn't by mapping your own domain to it), I'm increasingly likely not to read it: Medium caps monthly views unless you register and log in; I'm not going to, and I do hit that crap...  
  
News

**[Carnets](https://itunes.apple.com/fr/app/carnets/id1450994949?l=en&mt=8)**, a standalone'n'self-contained Jupyter notebook app for iOS, has hit the AppStore...  
  
...[**IPython** 7.5.0](https://ipython.readthedocs.io/en/stable/whatsnew/version7.html#ipython-7-5-0) is out...  
  
... and **Papermill**, the automation tool for parameterizing and executing notebooks, is out at [v1.0.0](https://github.com/nteract/papermill) _\[though I couldn't spot any informative release notes? —Ed.\]_  
  
Jupytext bumped up to [1.1](https://github.com/mwouts/jupytext/releases/tag/1.1.0) (and it's had at least one minor release since), with support for metadata being added to Markdown and R Markdown formats; Pandoc's Markdown format for Jupyter notebooks is also now available.  
  
If you fancy running **JupyterHub on Hadoop**, there's a new [guide](https://jcrist.github.io/jupyterhub-on-hadoop/) out... And new to me, this list of [JupyterHub deployments](https://github.com/jupyterhub/jupyterhub/blob/master/docs/source/gallery-jhub-deployments.md) _\[which also looks like it includes more than a few deployment guides... My own list, which I've been neglecting lately, along with lots of other things, is [here](https://github.com/innovationOUtside/ioc-infrastructure-review/wiki/Deployment-Guides)... —Ed.\]_.  
  
Via a [tweet](https://twitter.com/betatim/status/1116465352551145477) from @betatim, MyBinder stats suggest that _"~50TB of docker images cost us about $100 per week"_... _\[Just remember, free services have to be paid for someone, even if they really are free to the end-user...—Ed.\]_ If you're interested in helping keep MyBinder running, check out the [Interested in joining the mybinder.org operations team?](https://discourse.jupyter.org/t/interested-in-joining-the-mybinder-org-operations-team/761)thread on the Jupyter discourse site. For providing more general help, there are also plenty of open issues, some of which are good first issues _\[and not all of which require mad, indeed, any, coding skillz; such as this one on [Add\[ing\] a guide to pinning dependencies](https://github.com/jupyterhub/binder/issues/161) —Ed.\]_.  
  
Not content with providing Jupyter friendly cloud services to the geoscience community, it looks like the **PanGeo** folk are looking to build on lessons learned from developing their own platform to support other communities too. For example, [PanNeuro](https://arokem.github.io/2019-BRAINI-PanNeuro-slides/#/), which is looking to _"leverag\[e\] a community-based approach for big data neuroscience"_.  
  
And whilst not strictly Jupyter, given some of the bioscience related platforms described in elsewhere in this newsletter, it'll be interesting to find out how the British Neuroscience Association (BNA) intend to spend the £450,000 it's [just received](https://www.bna.org.uk/mediacentre/news/gatsby-funding/) from the Gatsby Charitable Foundation, in part to fund _"a significant programme of activities, promoting and supporting credibility a 'credibility in neuroscience' programme over the next ten years that will encompass reproducibility, replicability and reliability"_.  
  
In passing, I spotted another **EU infrastructure** project that runs a [JupyterHub instance](https://www.icos-cp.eu/jupyter), in this case providing access to European greenhouse gas datasets shared by the ICOS Carbon Portal_(ICOS, it seems, is the Integrated Carbon Observation System for recording and sharing "high quality and high precision greenhouse gas observations")_. If you're in **Australia** or New Zealand _**[Ecocloud](https://app.ecocloud.org.au/)**,_ the 'EcoScience Research Data Cloud and Data Enhanced Virtual Laboratory', provides access via [AAF](https://aaf.edu.au/) (Australian Access Federation) sign-on to [various services](https://support.ecocloud.org.au/support/solutions) including Jupyter notebooks, RStudio and virtual desktops _\[note that there are other services called ecocloud out there too.. —Ed.\]._  
  
More casually, if you want to run Jupyter notebooks on Glitch, [you can](http://jupyer on glitch https://glitch.com/edit/#!/jupyter-on-glitch)_\[h/t @mrchrisadams\]_.  
  
Apparently, IBM's [Watson Studio Desktop](https://www.ibm.com/support/knowledgecenter/SSBFT6_1.1.0/wsd/whatsnew.html) now supports Jupyter notebooks _\[I thought it already did?! —Ed.\]._  
  
The[April 2019 Release](https://devblogs.microsoft.com/python/python-in-visual-studio-code-april-2019-release/) of _Python in **Visual Studio Code**_ includes a **v****ariable explorer** and data viewer that let you _"easily view, inspect and filter the variables in your application, including lists, NumPy arrays, pandas data frames..."._  
  
This is a bit weird... [SeekWell](https://chrome.google.com/webstore/detail/seekwell/mefkdbekccdbdihhondepjimindlbpfg), a **Chrome Extension** for refreshing a Jupyter notebook: _"Simply open the extension while in a Notebook, choose how often you want the data to refresh, and click schedule. No more building complex scheduling scripts from scratch or manually running analysis and reports."_ \[[about](https://www.reddit.com/r/datascience/comments/beazsb/chrome_extension_for_scheduling_jupyter_notebooks/?depth=2)\]  
  
I can't quite get my head round how I'd use this, either... [jupyter-require](https://github.com/CermakM/jupyter-require)a Jupyter notebook extension that allows you to _"execute and manage custom JavaScript and CSS files and even create and load your own styles and scripts directly from Jupyter notebook"_. Handy when developing new widgets maybe?

Chart developers **Plotly** recently released [Plotly Express](https://medium.com/@plotlygraphs/introducing-plotly-express-808df010143d), a new high-level Python visualization library that provides _"a wrapper for Plotly.py that exposes a simple syntax for complex charts"_. _\[I'll be doing a round-up recent charting apps in the next edition or two of Tracking Jupyter...—Ed.\]_ Plotly also make a JupyterLab extension available _\[although not currently on Windows..? —Ed.\]_ for [rendering Plotly Dash apps as a separate window](https://github.com/plotly/jupyterlab-dash) in JupyterLab. The third party [dashserve](https://github.com/omegaml/dashserve) application will let you serve a Dash app straight from Jupyter Notebook or JupyterLab or publish a Dash app to a standalone server.  
  
If you like **pretty maps**, there's a nice notebook demo of how to [render a shapefile with datashader](https://github.com/tsloan1377/Misc_dataViz/blob/master/shapefile_to_datashader.ipynb). Loosely related _\[well, geo, innit...—Ed.\]_, [movingpandas](https://github.com/anitagraser/movingpandas) is a new trajectory class for **geopandas** that makes it easy to pull a Series of points into one or more lines.  
  
Effective **version control** with Jupyter notebooks is still a thing, especially if you want to keep check of the diffs. A [flow chart](https://pbs.twimg.com/media/D40zmJYW0AENcxx.jpg) to help has recently appeared _\[I couldn't offhand find it anywhere other than shared via a tweet? —Ed.\]_ that complements a recent _\[or recently updated? —Ed.\]_ [Nextjournal](https://nextjournal.com/schmudde/how-to-version-control-jupyter) article on the topic.  
  
Picking up on the Javascript magic **accessibility** tip from #TJ15 for generating speech from text and speaking them aloud from a code cell _\[and which seems to always autoplay whenever you load the notebook after its first run unless you guard it...—Ed.\]_, here's [another](https://twitter.com/jpvntra/status/1116770344218574849) way of doing it: if you have access to a bash shell,  _!say “Have you subscribed to Tracking Jupyter yet?”_, or in Python, with the message in a variable, _from os import system; system('say {}'.format(txt))_.

And finally, a tweet from the newly created @JupyterRedesign account has a recent [call to action](https://docs.google.com/forms/d/e/1FAIpQLScQcBH0LQPUQK2axtHjiMQuqUEtBBv82zsd11vyWYimKD4EMA/viewform): _"if you've got 5-10 minutes, please fill out our brief survey. We want to understand what's important to you when you're researching new tools for data science"_.  
 

For Your Listening Pleasure...
------------------------------

[cardiCast Episode 55](https://newcardigan.org/cardicast-episode-55-tim-sherratt/) features a live interview from the VALA Tech Camp with hacker and historian Tim Sherratt, Associate Professor of Digital Heritage at the University of Canberra, discussing his new obsession: Jupyter Notebooks. _\[I'm rehashing from the blurb...—Ed.\]_  
 

Weak Signals
------------

Various bits and bobs I noticed over the last few weeks...

*   more signs that people are naturally turning to using notebooks as a medium for writing books; eg this [book on Kalman Filters](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python);
*   a comment that every tutorial on the [Tensorflow 2.0 Alpha](https://www.tensorflow.org/alpha) site is backed by a Jupyter notebook [on GitHub](https://github.com/tensorflow/docs/tree/master/site/en/r2/);
*   increasing numbers of posts and articles like this — [One Step Closer to the “Paper of the Future”](https://researchdatamanagement.harvard.edu/blog/one-step-closer-%E2%80%9Cpaper-future%E2%80%9D) — describing narrative experiment reports in data managed research projects;
*   overview presentations of the Jupyter ecosystem show how it's growing; here's a recent example: [JupyterHub and Jupyter Notebook – A View Under the Hood](https://speakerdeck.com/jhermann/jupyterhub-and-jupyter-notebook-a-view-under-the-hood);
*   and a personal realisation that with academic publishing timescales such as they are, papers being published with Jupyter notebook support _now_, may well have been submitted a couple of years ago... _\[so, erm, if you aren't using notebooks yet, you may be late to the party... Here's a [quick search](http://search.arxiv.org:8081/?query=jupyter&byDate=1) if you want to check the competition on arXiv... —Ed.\]_

Events
------

This will be in the past by the time this newsletter, but I'm noting it anyway: a [meetup](https://www.meetup.com/Google-Cloud-AI/events/260248295/) at Google from April 25th, 2019, on _Jupyter notebooks at Netflix - Reusable execution in production using Papermill_. _\[Ah, now I get last night's 1.0.0 release... —Ed.\]_  
  
However, if you're in the Bay Area this weekend, there may still be time for you to get to Bloomberg’s San Francisco engineering office are hosting a set of Jupyter focused [Open Studio Days](https://go.bloomberg.com/attend/invite/jupyter-open-studio-day-2-3/) on Friday, April 26th from 2:00pm-6:00pm and Saturday, April 27th from 10:00am-6:00pm.  
  
The [Web4All](http://www.w4a.info/2019/hackathon/) conference in San Francisco is planning a hackathon around JupyterLab **accessibility** issues on May 15th-16th, 2019. A signup form is [here](http://at https://docs.google.com/forms/d/e/1FAIpQLSfn4f-qdLHD4UQ0QeeJpHKul1KIcjGeamVyfSWSpBEqT8uR8g/viewform) (closes April 30th).  
 

Making Connections 'n' Working Remotely...
------------------------------------------

lIf you want to use private **Google spreadsheets** as a data source for your Python notebooks, the [gspread](https://github.com/burnash/gspread) Python package provides a handy API, with auth handled via [OAuth](https://gspread.readthedocs.io/en/latest/oauth2.html). For a complete walkthrough of how to get connected, see [here](https://socraticowl.com/post/integrate-google-sheets-and-jupyter-notebooks/).  
  
When working with files stored using **_Google Cloud Storage_**, [gsutil](https://github.com/GoogleCloudPlatform/gsutil) provides a handy command line tool for accessing them.

Perhaps not surprising, Google **Colab** is doing what it can to move people away from native Jupyter environments by providing a way of [connecting to a local Jupyter server from Colab](https://research.google.com/colaboratory/local-runtimes.html). Part of the voodoo magic required comes in the form of the Google authored [googlecolab/jupyter\_http\_over\_ws](https://github.com/googlecolab/jupyter_http_over_ws) package which you'll need to install on your local server. _\[It seems like opensource is the default when it comes to enticing people in... —Ed.\]_  
  
One of the reasons for starting Tracking Jupyter was to help keep tabs on how things evolved. For example, how do you log in to a remote Linux server under ssh and fire up a notebook server there? From the _towardsdatascience.com_ blog, here's an [early recipe](https://towardsdatascience.com/remote-computing-with-jupyter-notebooks-5b2860f761e8) and here's a [contemporary one](https://towardsdatascience.com/running-jupyter-notebooks-on-remote-servers-603fbcc256b3).  
  
This is also just so much gobbledegook to me, but it may make sense to you... a [recipe](http://diegocarrasco.com/how-to-access-jupyter-notebooks-running-in-your-local-server-with-ngrok-and-an-intro-to-gnu-screen/) describing _How to access Jupyter Notebooks running in your local server with ngrok (and an intro to GNU Screen)_.  
 

At the Heart of it All...
-------------------------

_Kernels play a key role in the Jupyter ecosystem, so as promised previously, here's a little something just about them._  
  
Whatever kernel you're working on, you probably need to keep an eye on any messages passed to and from the kernel; the [jupyterlab-kernelspy](https://github.com/vidartf/jupyterlab-kernelspy) extension should help you do just that.  
  
Scores of projects run under the Apache banner _\[is there a Tracking Apache newsletter, I wonder? —Ed.\]_ but this is the first one I've seen that's incubating a Jupyter component: [Apache Toree](https://toree.incubator.apache.org/), _"a kernel for the Jupyter Notebook platform providing interactively access to Apache Spark"_. (Apache also maintain the [Apache Zeppelin](https://zeppelin.apache.org/) notebook platform too, of course.)  
  
For developers working in a Microsoft code environment, [ICSharpCore](https://github.com/SciSharp/ICSharpCore) is a C# .NET Core Jupyter kernel, providing a standard interface for [SciSharp STACK](https://github.com/SciSharp), a _"__.NET based Open Source Ecosystem for Data Science, Machine Learning and AI__"_. Microsoft also maintain [Microsoft/jupyter-core](https://github.com/Microsoft/jupyter-core/), a library to support writing Jupyter kernels in .NET Core: _"t__he Microsoft.Jupyter.Core library makes it easier to write language kernels for Jupyter using .NET Core languages like C# and F#. This library uses .NET Core technologies such as the ASP.NET Core Dependency Injection Framework to help make it straightforward to develop for the Jupyter platform"_. So now you know...  
  
If you're working on a new kernel out of the sharp space, I spotted this [implementation of the Jupyter wire protocol in D](http://code.dlang.org/packages/jupyter_wire) that allows _"a backend written in or callable by D to be a jupyter kernel"_.  
  
For developers looking at kernels that can talk easily to **IoT devices**, [adafruit/circuitpython\_jupyter\_kernel](https://github.com/adafruit/circuitpython_jupyter_kernel) provides a Jupyter kernel that will interact with Adafruit boards running [CircuitPython](https://circuitpython-kernel.readthedocs.io/en/latest/) over USB.  
  
And if it's **programmable logic** you want to talk to, this post on [i](https://www.hackster.io/adam-taylor/implementing-control-algorithms-with-pynq-python-b133ba)[mplementing control algorithms with pynq](https://www.hackster.io/adam-taylor/implementing-control-algorithms-with-pynq-python-b133ba) describes how the Xilinx [Pynq](http://www.pynq.io/) framework _"__enables application developers to use Python \[within Jupyter notebooks\] to connect with and use programmable logic in Xilinx heterogeneous SoCs, such as the Zynq and Zynq MPSoC"_.  
  
When it comes to **kernel management**, the [Jupyter Kernel Gateway](https://github.com/jupyter/kernel_gateway) _\[as mentioned in several previous issues...—Ed.\]_ provides _"a web server that provides headless access to Jupyter kernels. Your application communicates with the kernels remotely, through REST calls and Websockets rather than ZeroMQ messages"_. Alternatively, the _nteract_ [kernel-relay](https://github.com/nteract/kernel-relay) provides_"a GraphQL API for managing communication between a Jupyter kernel and front-end clients. The package allows users to control and monitor kernels. Through GraphQL queries and mutations, the API enables the user to launch kernels, subscribe to the status of a kernel, send Jupyter messages from a client to a kernel..."_.​  
  
For **polyglot notebook** programming, the [Script of Scripts (SoS) polyglot notebook](https://github.com/vatlab/SOS) or BeakerX [polyglot magic](https://nbviewer.jupyter.org/github/twosigma/beakerx/blob/master/doc/groovy/PolyglotMagic.ipynb) provide two ways to go _\[in addition to longstanding techniques for blending R'n'Py in the same notebook...—Ed.\]_ There's also the [scijava-jupyter-kernel](https://github.com/scijava/scijava-jupyter-kernel), a polyglot kernel based around the Scijava scripting languages, and originally created to work with ImageJ, that supports Groovy (default), Python, Beanshell, Clojure, Java, Javascript, Ruby and Scala.  
  
But here's another approach that made a brief appearance a couple of years ago: [allthekernels](https://github.com/minrk/allthekernels), _"a Jupyter kernel that multiplexes all the kernels you have installed. Specify which kernel a cell should use with >kernelname. If no kernel is specified, IPython will be used."_ It may just be a historical curiosity, or it may be worth revisiting as another way of doing things...  
  
If you ever need to run Jupyter kernels in a different **execution environments**, it seems that one way is to set environment variables manually in the kernelspec, or run commands before starting the kernel; [envkernel](https://github.com/AaltoScienceIT/envkernel) automates this process by dynamically creating a kernelspec against commandline arguments and then launching the kernel against that kernelspec.  
  
Finally, if you take a look at the notebook architecture diagram, control signals, data and state are communicated in various ways. The notebook UI talks to the kernel, but it also talks to widgets_ \[something I've got lined up for the next issue of Tracking Jupyter, or maybe the one after that, is a look at widgets that pass more than just simple widget control state back to the calling code...—Ed.\]_. Objects talk to the UI to negotiate what to display where (eg through _\_repr\__ methods). And on the backend, the kernel may talk to various data sources.  
  
The **[JupyterLab Data Explorer​](https://github.com/jupyterlab/jupyterlab-data-explorer)** is a new work in progress that implements a data registry that can _"show users datasets that have been registered and allow users to view those datasets, by relying on a series of data converters"_. The origins can be found in this [proposal for a JupyterLab data registry](https://github.com/jupyterlab/jupyterlab/issues/5548), with further discussion on [data converters in the data registry](https://github.com/jupyterlab/jupyterlab/issues/5831); a PR checklist summarising some of the relevant component parts can be found [here](https://github.com/jupyterlab/jupyterlab/pull/5857). Running it in MyBinder _\[the build is a long 'un... —Ed.\]_, displaying tables and chart previews over recognised datasets using the [nteract/dx](https://github.com/nteract/dx) data explorer _\[which I can't get to run on its own in a MyBinder notebook unless you [use the nteract frontend](https://github.com/nteract/dx/issues/7#issuecomment-486185820), but works fine in the JupyterLab Data Explorer demo... —Ed.\]_.  
 

Keeping Notebook Secrets
------------------------

Working on one of many side projects a week or two ago, I needed to make use of several secrets in part of a notebook (account credentials for calling a remote service).  
  
A crude way is to use password widgets to grab data, another is to use an input form and then call **_clear\_output()_** (imported from_ IPython.display_) at the end of the cell to clear any reported output.  
  
A slightly better way might have been to load in secrets from environment variables or a config file, but they still have the secret in plain text somewhere.  
  
So the best way is probably to use something like the [JupyterLab Credential Store](https://github.com/frankzickert/jupyterlab-credentialstore) (#TJ2) or this handy looking **[ipython-secrets](https://github.com/osteele/ipython-secrets)** extension, which lets you enter credentials once and then stores them in the system keyring. Usefully, the same line of code can be used to request credentials the first time, then reuse the stored credentials on future calls. There is a caveat though: "_the package is intended to reduce the likelihood of accidental disclosure of secrets in notebook source. It won't secure a secret from code that is running in the notebook; and it won't keep you from writing code that displays the secret in a notebook output cell -- in which case it has been disclosed to whoever can see the notebook_".  
  
This post on [Sharing non-public data in Jupyter notebooks](https://medium.com/codait/sharing-non-public-data-in-jupyter-notebooks-382d572a2a5b) considers some related issues with respect to accessing sensitive data from a notebook. More generally, care also needs to be taking when sharing notebooks for the displayed content they might contain, if for example analysis code can be shared, secrets for accessing data can be hidden, and analysis outputs (tables, charts, etc) should be eyes only for the authorised notebook user and should not be publicly shared.  
  
_\[Cleaning notebooks is a related issue, and something I have slated for an upcoming issue... This whole area is perhaps something that could also do with some "official" best practice guidance? —Ed.\]_  
 

Bio-stuff, Part 1...
--------------------

Also as promised in the previous issue, a selection of bio-related Jupyter bits and bobs, split into two sections because there was more than enough for one... _\[There was enough for a third section too, but that's for next time... —Ed.\]_  
  
[CoolBox](https://github.com/GangCaoLab/CoolBox) looks like a handy Jupyter notebook based **genomic data visulization** toolkit based on[pyGenomeTracks](https://github.com/deeptools/pyGenomeTracks), a Python module for _"plot\[ting\] beautiful and highly customizable genome browser tracks"._ Whilst it seemed to build okay on MyBinder _\[except for a missing Seaborn dependency, and space where it shouldn'__t be in a not__ebook magic call...—Ed.\]_ I struggled with the ftp data file downloads needed to try the demos out...  
  
[clustergrammer2](https://github.com/ismms-himc/clustergrammer2) is _"a__n interactive WebGL heatmap Jupyter widget built using the widget-ts-cookiecutter library"_ that can be used for **visualising gene expression data**. Example use cases can be found in [several notebooks](https://github.com/ismms-himc/EmbryoTimecourse2018).  
  
For 3D visualisations, **[mmtf-genomics](https://github.com/sbl-sdsc/mmtf-genomics)** provides an experimental project for mapping genomic data onto 3D protein structures in Jupyter Notebooks. Examples include mapping mutations with high allele frequencies as well as mutations from dbSNP to 3D structures. If you're a registered **CyVerse** user, you can [run _mmtf-genomics_ on CyVerse/VICE](https://github.com/sbl-sdsc/mmtf-genomics/blob/master/docs/vice_instructions.md) (_Visual Interactive Computing Environment_) using the [CyVerse/VICE JupyterLab](https://cyverse-visual-interactive-computing-environment.readthedocs-hosted.com/en/latest/user_guide/quick-jupyter.html) environment.  
  
A lot of data seems to be available on the CyVerse platform via the CyVerse [Data Store](https://www.cyverse.org/data-store), which is backed by the open source [iRODS](https://irods.org/) (_integrated Rule-Oriented Data System__)_ data management infrastructure. Access to iRODS services can be mediated using the [jupyterlab\_irods](https://github.com/towicode/IJab) extension _\[aka IJab for some reason?! —Ed.\]_ which provides _"an IROD connection filemanager for JupyterLab"_ that contains _"both a backend server using python-irods and a frontend for managing content"_.  
  
On the **automation** front, [BioJupies](https://amp.pharm.mssm.edu/biojupies/) \[[repo](https://github.com/MaayanLab/biojupies)\] is a web application _"that enables the automated creation, storage, and deployment of Jupyter Notebooks containing RNA-seq data analyses"_ \[[paper](https://www.cell.com/cell-systems/fulltext/S2405-4712(18)30432-0), and [another](https://www.sciencedirect.com/science/article/pii/S2405471218304320)\]. The process is described as follows:

> *   First, select an RNA-seq dataset you with to analyze. You can upload FASTQ files, gene expression tables, or use a search engine to browse over 6,000 public datasets published in the Gene Expression Omnibus.
> *   Second, add one or more computational tools to analyze the data. BioJupies currently supports 14 plugins to perform exploratory data analysis, differential gene expression, enrichment analysis, and small molecule queries.
> *   Third, generate the notebook with the desired settings. The notebook will be served to you through a URL, and can be easily downloaded and rerun on your local computer.

In a related vein, perhaps, [xml2gui](https://github.com/rheiland/xml2gui) provides a tool for **generating**** a custom Jupyter GUIs** from a PhysiCell config file _\[[PhysiCell](http://physicell.mathcancer.org/) is an __open source physics-based cell simulator for 3-D multicellular systems_ apparently... —Ed.\].  
  
From the same developer, there's also [tool4nanobio](https://github.com/rheiland/tool4nanobio), which _"helps auto-generate a Jupyter notebook GUI for PhysiCell-related models and output"_. In this case, _"the directory structure and content of the repository matches a template required for a nanoHUB tool installation \[although\] creating an actual nanoHUB tool is optional"_. _\[So I have no idea if these are the same, or different, or what?! The interesting thing, I think, is just the idea of finding creative ways of using notebooks to front config file UIs. —Ed.\]_  
 

Educationally Relevant
----------------------

In an educational context, it's nice to see several initiatives pushing things further.  
  
Prompted by goings on at DataCamp comes a port into a standalone interactive course of a course originally posted there: [Advanced NLP with spaCy](https://course.spacy.io/) . _\[If you haven't already seen it, you really should check it out... Reading through the rest of this newsletter can wait... —Ed.\]_ Using the _gatsby_ framework on the front end, and MyBinder, via _juniper.js_, on the back, this complements the Jupyter Book textbook approach with a more interactive, course like UI. The [source](https://github.com/ines/spacy-course) is available, along with a couple of repos for easy forking if you want to create your own interactive [Python](https://github.com/ines/course-starter-python) or [R](https://github.com/ines/course-starter-r) based course. For easy deployment, the creator suggests using _netlify_. _\[I couldn't help but wonder if how easy/hard it would be to create a Jupytext filter to publish one or more. ipynb notebooks to an appropriate format for rendering as a course? —Ed.\]_  
  
A few weeks ago, whilst using Selenium to automate the [bulk upload of notebooks to _nbgallery_](https://blog.ouseful.info/2019/01/21/bulk-notebook-uploads-to-nbgallery-using-selenium/), I wondered about whether it would be interesting to use Selenium to provide guided walkthroughs of using a Jupyter notebook. I still haven't explored that possibility, but maybe I don't need to now with the release by online course provider _Udacity_ of [Jupyter Graffiti](https://github.com/willkessler/jupytergraffiti), a tool for _"\[c\]reat\[ing\] interactive screencasts inside Jupyter Notebook that anybody can play back"_ ([intro post](https://blog.udacity.com/2019/04/interactive-screencasts-jupyter-graffiti-c-plus-plus-nanodegree.html)). _\[This is quite incredible... Make sure you watch all (short, 1-2 minutes) the videos... —Ed.\]_ A recorded Jupyter **notebook screencast** can reach out and highlight other cells in the notebook, such as code cells, as well as edit and run them. _\[I'm pretty sure this is more powerful than just novelty... I'm not sure how quick these things are to produce, either. I need to make some time to play... —Ed.\]_  
  
When it comes to providing notebooks in a self-contained learning environment, _CoCalc_ offers a lot of integrated support over vanilla Jupyter notebook installations. One good example is [TimeTravel](https://github.com/sagemathinc/cocalc/wiki/TimeTravel), the ability to revisit the various stages in a notebook's development using a time slider. [nbcomet](https://github.com/activityhistory/nbcomet)is an old Jupyter Notebook extension for **tracking notebook history** that dabbles with historical snapshots but it perhaps lacks the polish of the _CoCalc_ utility _\[I haven't had a chance to try nbcomet out yet, so I'm not sure if it still works... —Ed.\]_.   
  
The _CoCalc_ environment also provides a various features for [supporting real time collaboration](https://doc.cocalc.com/teaching-interactions.html), including chatrooms and realtime collaboration. Various Jupyter demos for **realtime collaboration** have appeared over the years, but never as a core offering. A recent demonstration of supporting realtime collaboration in a JupyterLab context can be found here: [ellisonbg/jupyterlab-rtc](https://github.com/ellisonbg/jupyterlab-rtc). For sharing files, the [JupyterLab Google Drive extension](https://github.com/jupyterlab/jupyterlab-google-drive) may also be handy _\[I'm not sure what happens if two people try editing the same notebook file or Jupytext dualled file at the same time? —Ed.\]_.  
  
_\[For an insight as to exactly what's involved in running something like CoCalc, and the resourcing issues that it entails, see this recent post from the founder on the question: [Should I Resign From My Full Professor Job To Work Fulltime On Cocalc?](http://blog.sagemath.com/2019/04/12/should-i-resign-from-my-full-professor-job-to-work-fulltime-on-cocalc.html)\]_  
  
I know _\[think?! —Ed.\]_we use the [jupyterhub/ltiauthenticator](https://github.com/jupyterhub/ltiauthenticator) for providing access to a JupyterHub instance fronting notebooks that run on Azure under Kubernetes, but I'm not sure if this might also be useful? A SAML Authenticator in the form of [jupyterhub-samlauthenticator](https://github.com/bluedatainc/jupyterhub-samlauthenticator)?  
  
Running a JupyterHub server in a small, rural, educational establishment without tech support can be an issue. So what if you could get it out of the box, in a box, cheaply and affordably? [Conjuring: A Self-Contained Jupyter Hub For Teaching](https://kingsgeocomputation.org/2019/04/25/conjuring/), from the geocomputation folk at Kings College is proposing just that with a _"robust, low-powered, self-contained server platform to support the teaching of computing using any web-enabled device in classroom, workshop, and community contexts"_. The proposal goes on:

> \[S\]ystems will have Ubuntu Linux installed and be configured so that they will launch both an ad-hoc WiFi network and a containerised version of Jupyter Hub on start-up. The container can be pre-loaded with all instructional materials – code, documentation, and data – for a single day or an entire term, enabling a teacher with minimal knowledge of computing as a whole (beyond what they are actually covering in class) to start teaching simply by plugging in the power cable and turning on the machine!

Picking up on the bio and edu themes together, _[TeachOpenCADD](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0351-x) _provides an interesting overview of _"a teaching platform developed by students for students, using open source compound and protein data as well as basic and CADD-related Python packages"_ \[[repo](https://github.com/volkamerlab/TeachOpenCADD)\]. It probably won't surprise you to hear that Jupyter notebooks have a part to play...  
 

Robots may be out there, but still only on the horizon?
-------------------------------------------------------

Not totally on the Jupyter topic, but... The **RoS (Robotics Operating System)** widget helpers mentioned in #TJ15 are great for folk with a ROS setup already in place, but if you _haven't_, there's still a need to get ROS running somehow _\[and ideally with a simulator, in case you don't have any appropriate robots to hand...—Ed.\]_ So if you do want to get up and running from scratch, this [docker-ros-vnc](https://github.com/henry2423/docker-ros-vnc) container may be useful... _\[Open a terminal once in the remote desktop and run : gazebo. Then, erm,... —Ed.\]_   
  
Elsewhere, this [tutorial](https://github.com/JdeRobot/RoboticsAcademy) \[[more](http://jderobot.org/Robotics-Academy)\] looks like it may have some pieces that could also be useful in putting together a basic open educational robotics environment. And here's the first part of [another tutorial](http://moore-mike.com/ros-analysis-part-1.html).  
  
_\[As things stand, things are still just too disjoint for me to be able to easily get up and running with some ROS widget demos? I need to spend an hour or two trying to put some pieces together... —Ed.\]_  
  
Looking further around, I also notice this online [ROS Development Studio](http://www.theconstructsim.com/rds-ros-development-studio/) (limited free plan available), with shareable code in the form of ["ROSjects"](http://www.theconstructsim.com/rosjects/). And not just one, but also another: [Yonohub](https://yonohub.com/), a _"cloud-based system for designing, sharing, and evaluating complex systems, such as Autonomous Vehicles, ADAS, and Robotics"_ \[[about](https://towardsdatascience.com/yonohub-autonomous-vehicles-using-blocks-ef4a1838d92c)\].  
  
If you do want to get started with physical robots, there are [demo notebooks](https://github.com/NVIDIA-AI-IOT/jetbot) available for the DIY [NVIDIA Jetbot](https://github.com/NVIDIA-AI-IOT/jetbot/wiki). Amazon also have a robot toy, ([AWS DeepRacer](https://aws.amazon.com/deepracer/); not out yet?) that can be [programmed](https://docs.aws.amazon.com/deepracer/latest/developerguide/train-evaluate-models-using-sagemaker-notebook-initialize-instance.html) via AWS Sagemaker notebooks. As for their [AWS RoboMaker](https://aws.amazon.com/robomaker/) online robotics studio, I have no idea..._ \[I find AWS largely unusable in terms of the time it takes to find out what a service does and how to get up an running with it... —Ed._  
 

Bio-stuff, Part 2...
--------------------

Way back when in [#TJ7](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-seventh) I mentioned the _SciServer_ scientific research platform that serves notebook fronted containers that incorporate custom software environments tuned to particular research areas (fluid dynamics, for example, or astronomy). Examples like the CyVerse and ICOS Carbon Portal JupyterLab environments suggest that off-the-shelf availability of notebook mediated hosted environments, as well as notebook mediated subject-specific containerised environments, are increasingly well established. So here are a couple more examples from the biosciences area to reinforce that point further.

To start with, there's** [GenePattern](http://software.broadinstitute.org/cancer/software/genepattern/)**, a _"platform for reproducible bioinformatics" _that has been extended to use notebooks in a couple of ways.[GenePattern Notebook](http://genepattern-notebook.org/) provides an interactive notebook interface via a JupyterHub \[[repo](https://github.com/genepattern/genepattern-notebook)\], extended with hooks into other GenePattern services using the [GenePattern Python library](https://github.com/genepattern/genepattern-python) and a [geneapattern/ntools](https://github.com/genepattern/nbtools) package that claims to provide _"\[a\]__ framework for creating user-friendly widgets and tools in Jupyter Notebook"_ _\[I'm not sure what it actually offers over a vanilla ipywidgets install? —Ed.\]._ The [GenePattern Notebook Repository](https://github.com/genepattern/notebook-repository)implementsa second webservice, intended for use with with JupyterHub's Services API, that can be used to share, publish and preview Jupyter Notebooks._\[It would be interesting to see how this compares with nbgallery? So that's another thing for the to-do list... —Ed.\]_  
  
What looks to be rather more elaborate in terms of managing workflows, the [KBase Narrative Interface](https://kbase.us/narrative-guide/) provides a graphical user interface for accessing functionality and data from The Department of Energy _Systems Biology Knowledgebase_ — aka KBase — which seems to be _"a collaborative, open environment for computational systems biology analysis of plants, microbes and their communities"_. _\[This reminds me a bit of the SoS polyglot notebook and workflow tooling, but I don't have the energy right now to try to make sense of either of them...—Ed.\]_  
  
As well as academic platfroms, it also looks like there are commercial platforms with Jupyter UIs too. Like One Codex, who've just blogged this post on [Interactive microbiome analysis with Jupyter notebooks](https://www.onecodex.com/blog/2019/04/25/onecodex-jupyter-notebooks-for-data-viz/) to plug a "big update" to their [notebooks platform](https://docs.onecodex.com/docs/notebooks).  
  
On the platform front, [Chembience](https://github.com/chembience/chembience) provides an example of a **Docker based platform** for _"supporting the fast development of chemoinformatics-centric web applications and microservices"_ with _"a clean separation between your scientific web service implementation and any host-specific or infrastructure-related configuration requirements"_. _\[I have no idea either... but there's a pretty architecture diagram... —Ed.\]_  
  
At the self-contained Docker container level, [NanoDJ](https://github.com/genomicsITER/NanoDJ) provides _"a Jupyter notebook integration of tools for simplified manipulation and assembly of DNA sequences"_ produced by Oxford Nanopore Technologies (ONT) such as the MinION portable sequencer \[[paper](https://www.biorxiv.org/content/10.1101/586842v1)\].  
  
More generally, [Dugong](https://dugongbioinformatics.github.io/) \[[repo](https://github.com/DugongBioinformatics/Dugong)\] is a **s****cientific Linux Container** _"especially designed for scientific computational analysis, mainly of bioinformatics and computational biology__"_.  
  
When it comes to container-based application shelves, the [BioContainers](https://biocontainers.pro/#/) project posits an open-source and community-driven framework for software standardization using predefined **bioinformatics containers** \[[paper](https://www.ncbi.nlm.nih.gov/pubmed/28379341) and list of [container Dockerfiles](https://github.com/BioContainers/containers)\]. There's also [BioShaDock](http://bioshadock.genouest.org/), _"a community driven bioinformatics shared Docker-based tools registry"_ \[[paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4743153/)\]. _\[Splitters?! —Ed.\]_For a recent-ish review of reproducibility in the life sciences, see for example [Practical Computational Reproducibility in the Life Sciences​](https://www.cell.com/cell-systems/fulltext/S2405-4712(18)30140-6). Or maybe [Computational Proteomics with Jupyter and Python](https://www.ncbi.nlm.nih.gov/pubmed/30980332).  
  
 
