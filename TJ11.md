Welcome to this eleventh edition of the _Tracking Jupyter_ newsletter (#TJ11).  
  
Subscription numbers are going nowhere, so if you think this newsletter is useful, and/or you share links to news items you've picked up from it, please also [share a link](https://tinyletter.com/TrackingJupyter) to the newsletter too. For searching back copies, also remember there's now a [searchable Tracking Jupyter newsletter archive](https://github.com/TrackingJupyter/archive) on Github.  
 

News
----

Depending on when you read this, later today (Friday, February 1st, 2019, 5pm GMT), [Episode 13 of the ](https://app.livestorm.co/quansight/open-source-directions-ep-13-jupyter-ecosystem)[Open Source Directions webinar series](https://app.livestorm.co/quansight/open-source-directions-ep-13-jupyter-ecosystem) will feature a discussion on the **Jupyter Ecosystem** with core contributors with Matthias Bussonnier and Carol Willing.  
  
Microsoft have just released [jupyter-Kqlmagic](https://github.com/Microsoft/jupyter-Kqlmagic/) for running **KQL** (Kusto Query Language) queries against Azure Data Explorer, Application Insights, and Log Analytics data sources ([about](https://azure.microsoft.com/en-us/blog/analyze-data-in-azure-data-explorer-using-kql-magic-for-jupyter-notebook/), [docs](https://docs.microsoft.com/en-us/azure/data-explorer/kqlmagic)). Plot.ly visulisations are also supported using integrated KQL render commands.  
  
So who doesn't like a good survey? _\[erm... —Ed.\]_ Via my feeds, I notice this survey on **Options for Sharing/Running/Presenting Jupyter Notebooks **_"to help the data science community learn about options for running, sharing, collaborating on, or presenting Jupyter Notebooks"_. It's quite simplistic _\[maybe too simplistic? —Ed.\]_ but these round-ups can be useful. So if you have a couple of minutes, [take the survey](https://docs.google.com/forms/d/e/1FAIpQLSfcsX-dDo65D7MfOABHYGrRPLr4C313_aGsAPgSN8hHj9hgAA/viewform).   
  
Fancy running Jupyter notebooks natively on **iOS**? Then [Python3\_iOS](https://github.com/holzschu/python3_ios​), _"a patch of Python-3.7.1, designed to make it compile on iOS"_, may be worth checking out. It claims to run Jupyter locally, _"without a network connection"__\[compared to the Juno iOS app, which requires you to connect to a remote kernel. —Ed.\]_. It also seems as if you're limited as to how many notebooks you can have running at any one time because of the various hacks required to get things to run properly on iOS...  
  
_\[If you're looking to run notebooks on **Android**, I found an [old recipe here](http://www.leouieda.com/blog/scipy-on-android.html) and an unrelated [demo video here](https://www.youtube.com/watch?v=hf77RTm_fdY).—Ed.\]_  
  
Notebooks of the future? This [Twitter thread](https://twitter.com/danyx23/status/1089997263835983872) describes some upcoming features in the [NextJournal](https://nextjournal.com/) workflow including the ability _"to execute notebooks by webhook_" _\[so presumably ThebeLab/Volia+Binderhub like?—Ed.\]_. NextJournal is something I need to look at. The way they support [environment transclusions](https://nextjournal.com/nextjournal/transclusions) (versioned imports essentially) into articles looks interesting from an authoring workflow point of view. _\[From a quick look at the screenshots, it reminds me of Stencila.—Ed.\]_  
  
If Jupyter is your Valentine, and you're in Amsterdam on February 14th, there's a [Jupyter meetup](https://hal24k.com/jupyter-meetups) starting at 17.15...  
  
Dates for workshops funded under the Bloomberg funded **Jupyter Community Workshop** scheme are starting to appear. In the UK, there's a series of workshops on [getting started with Binderhub](https://www.eventbrite.co.uk/e/boost-your-research-reproducibility-with-binder-manchester-registration-55331997494), and in Berkeley, a developer/HPC engineer workshop on using [Jupyter for Scientific User Facilities and High-Performance Computing](https://blog.jupyter.org/jupyter-community-workshop-jupyter-for-scientific-user-facilities-and-high-performance-computing-3afa4a990086).  
  
Earlier this week, **ArcGIS** [announced](https://www.youtube.com/watch?v=vmbadpQtqq4&index=8&list=PLaPDDLTCmy4bVdjIydl5pGZ25E_8O-pgB&t=0s) that Jupyter notebooks will soon be available via ArcGIS Enterprise and ArcGIS Online. Searching around, I noticed that a temporary notebook server seems to be available at [https://notebooks.esri.com](https://notebooks.esri.com/). _\[The demo notebooks are date-stamped several months ago, so I wonder how long that server has been around? —Ed.\]_  
  
If you want to know what the most popular Jupyter notebook tagged repos were on Github over the last day, week, or month, try [this query](https://github.com/trending/jupyter-notebook?since=monthly) \[[via](https://medium.com/@trekhleb/most-trending-jupyter-notebooks-of-december-on-github-c05529d04b40)\].  
 

Picking Up...
-------------

Riffing on the HPC workshop announcement, if HPC's your thing, [garstka/idact](https://github.com/garstka/idact) is _"a Python 3.5+ library that takes care of several tedious aspects of working with big data on an HPC cluster"_. If you _"h__ave access to an HPC cluster with Slurm as the job scheduler, \[w\]ould like to parallelize ... computations across many nodes using Dask.distributed, a library for distributed computing \[and\] \[p\]erform computations on Jupyter Notebook\[s\]"_ this may be handy.  
  
I've previously mentioned the Juniper Javascript package for executing code from an arbitrary webpage agains a remotely launched Binder kernel ([#TJ7](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-seventh)); here's a nice example of it being used in the wild as part of the [_spacy_ natural processing toolkit documentation](https://spacy.io/usage/linguistic-features#pos-tagging).  
 

Topping Up...
-------------

I first mentioned [nbgallery](https://nbgallery.github.io/) for sharing notebook amongst a team in [#TJ7](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-seventh) and I've finally got round to having a proper play with it: a walkthrough write-up of it is available [here](https://blog.ouseful.info/2019/01/28/first-play-with-nbgallery/).  
  
Via the same developers, I also spotted the **[ipydeps](https://github.com/nbgallery/ipydeps)** extension which provides _"a friendly wrapper around pip for installation of packages directly within Jupyter notebooks"_.  This means you can install packages via Python, rather than the _%pip_ IPython magic ([#TJ8](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-eighth)) that lets you install packages directly into the current kernel. _\[I'm assuming that the ipydeps extension also makes sure the package is installed into the appropriate Python environment...—Ed.\]_  
  
I've mentioned several ways of connecting to SQL databases in previous newsletters, and here's another: a recipe for how to [connect to a remote **SQL Server** instance](https://www.datasciencecentral.com/profiles/blogs/remotely-send-r-and-python-execution-to-sql-server-from-jupyter) from a Jupyter notebook.  
  
One of the many ways notebooks can be used is to define simple APIs exposed via the **[Jupyter Kernel Gateway](https://github.com/jupyter/kernel_gateway)**. [This repo](https://github.com/natbusa/kernelgateway_demos) demos a couple of simple examples, and makes me wonder: has anyone got a simple demo showing how to use[Jupyter Server Proxy](https://github.com/jupyterhub/jupyter-server-proxy) to launch a self-starting kernel gateway API service on MyBinder?  
 

Something for the Devs / Dev-Ops Crew
-------------------------------------

Trying to use notebooks for _everything_ may or may not make sense, but I think we're still at the stage of working out what easy-access notebook style computing _is_ appropriate for, and workflows associated with it. DevOps is most definitely _not-my-area_ _\[I'm not sure anything is...? —Ed.\]_ but that doesn't prevent me from looking to see what jigsaw pieces might be out there and how they might start to fit together.  
  
This post on [Using Jupyter Notebooks as your cloud IDE for DevOps](https://medium.com/@guyernest/using-jupyter-notebooks-as-your-cloud-ide-for-devops-a49c03e5cb3f) provides a walkthrough of how you might use a notebook environment to explore, and document, the _"__develop\[ment of\] a mechanism to save 70% of the cost of notebook instances in SageMaker, using automatic stop and start at the end and beginning of every working day_".  
  
The Japanese National Institute of Informatics (**NII**) also has a page up on [Literate Computing for Reproducible Infrastructure](https://literate-computing.github.io/index.html) (**LC4RI**) describing workflows and tooling based around a _"Jupyter based toolset for an infrastructure engineer"_. _\[I'll post a roundup of the extensions that make up this toolkit in a later newsletter, once I've had a chance to try them all out. —Ed.\]_  
  
In terms of kernel support, this [Ansible kernel](https://github.com/ansible/ansible-jupyter-kernel)  provides a Jupyter notebook kernel that allows _"Jupyter to interface directly with Ansible and construct plays and tasks and execute them on the fly"_. _\[By the by, there are quite a few Ansible playbooks out there showing how to set-up various Jupyter mediated environments. I've started trying to build a directory of them, which I'll share as and when it's presentable. So if you have anything you'd like to share in that regard, drop me a line... —Ed.\]_  
  
And in terms of package support, the [Rubix](https://github.com/Nurtch/rubix) python package _"__makes it easy to perform common DevOps tasks ... such as plot\[ting\] Cloudwatch metrics \[or\] roll\[ing\] back your ECS/kubernetes app"_ inside Jupyter notebooks.  
 

Continuous Build and Test
-------------------------

For testing purposes, the [Robot Framework IPython kernel](https://github.com/robots-from-jupyter/robotkernel) provides notebook support for the Robot Framework, a _"generic test automation framework for acceptance testing and acceptance test-driven development"_. The easiest way in is probably via their [workshop resources](https://robots-from-jupyter.github.io/), which includes a RobotLab installer package ([repo](https://github.com/robots-from-jupyter/robotlab)) to get you going.  
  
The Robot Framework demos also show [how to grab Selenium screenshots](https://datakurre.github.io/robotframework-seleniumscreenshots/) within that context. \[_By the by, I recently posted a code fragment showing how to grab [HTML styled pandas dataframes as PNG files using Selenium](https://blog.ouseful.info/2019/01/16/converting-pandas-generated-html-data-tables-to-png-images/) and another on [using Selenium to bulk upload notebooks to nbgallery](https://blog.ouseful.info/2019/01/21/bulk-notebook-uploads-to-nbgallery-using-selenium/).—Ed.\]_  
  
For anyone looking at how to get started using Github mediate continuous build services, the Binder [continuous-build](https://github.com/binder-examples/continuous-build) example repo shows how to use CircleCi to build an image from a repo using _repo2docker_ and then push it to Docker Hub.  
  
Continuous testing of notebooks is something I still need to work out for myself. This repo — [ghego/travis\_anaconda\_jupyter](https://github.com/ghego/travis_anaconda_jupyter) — looks like it provides a simple/minimal demonstration of running a notebook checked into Github using Travis but I'm yet to find any baby steps tutorials describing how to set up automated notebook testing from scratch. There are also some notebook testing frameworks out there — [computationalmodelling/nbval](https://github.com/computationalmodelling/nbval) (_"a py.test plugin to validate Jupyter notebooks"_) and [opengeophysics/testipynb](https://github.com/opengeophysics/testipynb), for example, or for IJulia notebooks, [cstjean/NBTesting.jl](https://github.com/cstjean/NBTesting.jl) — but again, no walkthroughs of the whole process that I've found as yet.  
 

Simple Security Recipes
-----------------------

One thing I've noticed, particularly in the education sector, is have-a-go educators _\[Erm, like, erm, looks around, whistles, kicks dust, etc... —Ed.\]_ running their own Jupyter notebook servers for their students. For whatever reason, there seems to be some sort of disconnect between innovator-educators and IT service providers in a wide variety of educational institutions. _\[There's also a skills gap that I for one fall into.—Ed.\]_ Whilst its increasingly straightforward to launch your own public service using a web host such as _Digital Ocean_, sort of..., doing so securely requires specialist security knowledge that takes time to develop. User facing Jupyter services increasingly come with auth built in, although it can still be a challenge for end-user have-a-go administrators to get it working as intended (or indeed, at all).  
  
Some recipes are starting to appear that demonstrate how to set up https and simple http authentication as additional levels of _ad hoc_ security, such as this set of blog posts on [Installing Jupyterhub Using Digital Ocean](https://pythonforundergradengineers.com/installing-jupyter-hub.html) and this post on [HTTP Authentication for Jupyter Notebooks](https://www.databulle.com/blog/code/jupyter-notebook-apache-proxy.html) but it'd be good to see a proven, and approved, DIY manual out there. Some good architectural diagrams or cartoons, showing what pieces should go where, and for what purpose, would also be handy... _\[So if you know of any...?—Ed.\]_  
 

Culture, Practice, Workflow
---------------------------

Following on from the election mapping example notebooks in [#TJ10](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-tenth), here's a set of Jupyter notebooks for [post-election audits​](https://blog.jupyter.org/jupyter-notebooks-for-post-election-audits-4bdd13d3e800)  demonstrating risk-limiting audits (RLA), _"statistical check\[s\] that the reported outcome (the reported winner(s), as opposed to exact vote totals) of an election is correct."_  That sounds interesting in its own right, but there's more: _"\[i\]n each city, I projected the notebook running locally on my laptop on a screen for about 30 local election officials. They could observe me entering the reported vote totals for each candidate and the 20-digit random seed to initialize the pseudo-random number generator, then see the sampled ballots appear on the screen in a nicely formatted table."_ If you;ve been to a developer conference in the last couple of years, you've probably seen notebooks being used to support live coding demos. But this is a great example of how notebooks can be used as a communicative medium in a more general setting. _\[So how long before notebook mediated presentations start appearing alongside spreadsheets, Tableau and PowerBI dashboard presentations more generally? —Ed.\]_  
  
In terms of organising notebook fronted projects, [Cookiecutter Data Science — Organize your Projects — Atom and Jupyter](https://medium.com/@rrfd/cookiecutter-data-science-organize-your-projects-atom-and-jupyter-2be7862f487e)  describes the  [cookie-cutter-datasceince package](https://github.com/drivendata/cookiecutter-data-science) _"a logical, reasonably standardized, but flexible project structure for doing and sharing data science work"_. The R world is rich with these, quick commandline calls for setting up directory structures and organising your work. _\[The next little data project I start from scratch, I'll try to give this a run through... —Ed.\]_  
  
When it comes to produce documentation from notebooks, I've previously mentioned [nbsphinx](https://github.com/spatialaudio/nbsphinx) ([#TJ5](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-fifth); [docs](https://nbsphinx.readthedocs.io/en/0.3.5/)). But here's a complementary approach: notebooks from Sphinx documentation. [sphinxcontrib-jupyter](https://github.com/QuantEcon/sphinxcontrib-jupyter) provides tooling that allows you to _"build a collection of Jupyter notebooks for Sphinx Projects \[from a Sphinx repo\]"_. In particular, Sphinx directives allow you to define executable code cells, markdown cells, markdown cells containing styled code blocks, as well as defining slides and slide types (subslide, fragment, notes, etc.). In an educational context, _"\[t\]he extension has support for :class: solution on code-blocks. This allows for the compilation of two sets of notebooks, one containing solutions and one without". S_o if you want to write notebooks as .rst and then generate executable notebooks from it using Sphinx, you can._ \[I wonder if this could be integrated with Jupytext ([#TJ6](https://tinyletter.com/TrackingJupyter/letters/tracking-jupyter-newsletter-the-sixth))? —Ed.\]_  
 

Notebooks and Extensions
------------------------

The majority of notebook examples that I come across are still python based, but occasionally other kernels make an appearance. This is the [first _IfSharp_ example I've spotted](https://areslazarus.com/archive/cntk-102-hidden-layers-live-progress-report-widget/), on training a feed forward network, It also includes a nice interactive widget that display training progress.

Tabular display is one of the things that keeps evolving in notebooks, with rich renderers starting to appear for all sorts of objects defined in various Python packages. For example, here's a rich display hook that provides an HTML renderer for **numpy arrays**: [numpy-html](https://github.com/agoose77/numpy-html). And at the time of writing, whilst the [colorlover](https://github.com/jackparmer/colorlover) _"color scales in Python for humans"_ palette viewer requires explicit calls to notebook _HTML()_ display machinery, it would only take a small PR to add a rich display hook to it...  
  
If it's **Sankey diagrams** you prefer, here's a new [ipysankeywidget](https://github.com/ricklupton/ipysankeywidget).  
  
Another way I've noticed notebooks being used is for **end user application development** / rapid application development where users role their own tools to help process data _\[that is, using notebooks to create and run applications, rather than provide reproducible scripts.—Ed.\]_ For example, here's a simple widget based tool for **labelling datasets**: [LabelMyTextWidget](http://LabelMyTextWidget).  
  
I've also noticed in my own doodlings a hybrid approach of writing linear code narratives, interspersed with exploratory widget interactions. An immediate use case of my own doesn't spring immediately to mind, but this [ipython\_blocking](https://github.com/kafonek/ipython_blocking) magic may be useful if you need to pause execution in a notebook until a particular widget, such as a dropdown list, changes value.  
 

Domain Specific Notebooks - NLP
-------------------------------

I have to admit, the [Yandex School of Data Analysis](https://yandexdataschool.com/), _"__a free Master’s-level program in Computer Science and Data Analysis, which is offered by Yandex since 2007"_is new to me _\[it's presumably akin to many of the vendor programmes offered by the likes of [Google AI](https://ai.google/education/), IBM's [Cognitive Class](https://cognitiveclass.ai/), [Microsoft AI School](https://aischool.microsoft.com/en-us/home), Amazon's [AWS Machine Learning Training](https://aws.amazon.com/training/learning-paths/machine-learning/) and so on? —Ed.\]_. But if you fancy trying out some of their materials, here's the repo for their notebook rich, Binderised, [Yandex Natural Language Processing course](https://github.com/yandexdataschool/nlp_course).  
  
If you fancy following the [Applied Natural Language Processing (Spring 2019)](https://github.com/dbamman/anlp19) course at Berkeley, it looks as if notebooks in support of that course may be being added in near real time as the course progresses. _\[In an organisation that takes years, literally, to produce course materials, I can only wonder at such just-in-time production! Except when we're really late with the schedule, of course!—Ed.\]_  
  
Or maybe [Deep Learning for Natural Language Processing: Tutorials with Jupyter Notebooks](https://insights.untapt.com/deep-learning-for-natural-language-processing-tutorials-with-jupyter-notebooks-ad67f336ce3f) from _untapt_ appeals?   
  
Not strictly Jupyter related, but possibly of interest to IPython notebook NLP developers, [StanfordNLP](https://stanfordnlp.github.io/stanfordnlp/) features a _"full neural network pipeline for robust text analytics ..., pretrained neural models supporting 53 (human) languages featured in 73 treebanks \[and a\] stable, officially maintained Python interface to CoreNLP_".  
  
If notebook backed corporate research is more your thing, here's a [repo](https://github.com/yhilpisch/dnanlp) providing Python code and Jupyter Notebooks to support the Dow Jones applied research paper "[Unlocking the Hidden Potential of Unstructured News Data with NLP — Understanding Advanced Analytics through Real-World Case Studies](http://go.dowjones.com/dna-research-paper)".  
  
And finally, if you just want to look at some pretty pictures, the [svgling](https://github.com/rawlins/svgling) package provides notebook support for linguistic tree drawing using SVG that can _"__be used as a drop-in replacement for \[nltk\] Tree's png-based repr in Jupyter__"_ \[[issue](https://github.com/nltk/nltk/issues/1765#issuecomment-445901842)\]. The spacy [displacy visualisation tool](https://spacy.io/usage/visualizers) also works natively within notebooks. Not strictly _linguistic_ tree visualisation, [show\_ast](https://github.com/hchasestevens/show_ast/) might be useful when considering _programming_ languages: some magic that allows you display abstract syntax trees, generated from code, in a notebook.
