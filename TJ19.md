Welcome to this nineteenth edition of the _Tracking Jupyter_ newsletter (#TJ19).  
  
The backlog is getting ever bigger as I try to contextualise things a little bit more, whilst still keeping the newsletter wordcount down _\[?! —Ed.\]_. I've no idea if that's a useful thing to try to do even for me, let alone you, but it's probably how it's gonna be for a few issues yet...

News
----

Exciting [news](https://discourse.jupyter.org/t/the-binder-federation/1286) from the BinderHub team: MyBinder is now a **federated service**. There are there are now **two** clusters serving requests for mybinder.org, with [OVH](https://www.ovh.co.uk/) adding the second cluster to the mix, although the everyday user shouldn't notice much difference at all. The announcement also makes the following appeal to potential providers: _"if your institute or company wants to help run mybinder.org by hosting a small cluster, let us know. We can send you traffic :-) 2% of mybinder.org’s traffic corresponds to about 4-10 user pods running at any one time which can fit on a single moderately large instance"_.  
  
The Binder team are also running a really, really short [user survey](https://docs.google.com/forms/d/e/1FAIpQLSd3fiLCMuQsc48_ga2q_FJFqgFcVUkie7RBex4DtzzOyyNWHg/viewform) It shouldn't take you more than a minute or two to complete, so you might as well do it now...  
  
If you need a quick refresh on **extensibility** opportunities in all areas of the Jupyter ecosystem, Yuvi Panda has posted this [really handy overview](https://blog.jupyter.org/99-ways-to-extend-the-jupyter-ecosystem-11e5dab7c54). From magics and widgets, through Jupyterlab, server and notebook extensions, kernels and content managers, spawners, content providers and build packs, it's a rich world out there that you can also make richer in, oh, so many ways...  
  
Another way to keep up is to listen in... So if you're around, [via](https://discourse.jupyter.org/t/elife-community-call-on-tools-for-increasing-reproducibility-in-research-mon-24-june-4pm-bst/1427) the Jupyter discourse site, there's an **ELife community call** on _"tools for increasing reproducibility in research"_ on Monday, 24the June 4pm BST; and the next **Jupyter Community Call** [takes place](https://discourse.jupyter.org/t/jupyter-community-calls/668) online on Tuesday, June 25th, 2019 at 9am PST.  
  
There's also a call out for expressions of interest in a Binder related workshop in Oslo in September. So if you fancy that, expressing an interest [here](https://discourse.jupyter.org/t/jupyterhub-binder-workshop/1419) might help it happen...  
  
In slogan land, **_JaaS - Jupyter As A Service_** is now a thing, making an appearance as Lentiq's current marketing [strapline](https://lentiq.com/jupyter-as-a-service)_\[doh! Why didn't I coin that as a Tracking Jupyter section heading ages ago?!—Ed.\]_. It'll be interesting to see if it starts to appear as a phrase more widely used...  
  
Not strictly Jupyter, but interesting nonetheless, a new early days, proof of concept, in-browser publishing and code executing blogging platform, [epiphany.pub](https://epiphany.pub/). [Billed](https://medium.com/@shiyan/epiphany-pub-jupyter-mix-with-medium-474e33251aa8) as _"Jupyter mixed with Medium"_, a read/write web experience in many ways reminiscent of [Observeable](https://observablehq.com/) notebooks, it currently lets you add markdown (with equation support), Javascript and Python cells. Code is executed in the browser, with code outputs such as charts rendered in place. Interestingly, the Python execution support seems to come from [pyodide](https://github.com/iodide-project/pyodide). Support for signing in with a Github, Bitbucket or GitLab account, and then the ability to save edited documents in a repo there, looks like it should be on the cards but doesn't seem to work for me at the moment _\[erm...did I just give away my credentials again?! —Ed.\]_. See the [docs](https://shi-yan.github.io/epiphany/) for a more detailed overview. A detailed comparison with [NextJournal](https://nextjournal.com/) or [Stencila](https://stenci.la/) could be interesting...  
  
If you spend a lot of time poking around in a browser developer console, or using the _requests_ package to try to make sense of an undocumented API, [ipyrest](https://github.com/deeplook/ipyrest) may help: _"an emerging Jupyter notebook widget for exploring RESTful APIs. It has two main goals: provide a more convenient interface in the spirit of **Postman**, and allow for plug-in components, starting with output renderers for various MIME types, e.g. GeoJSON, see below"_.  A requests visualiser, essentially, that lets you explore headers and cookies as well as API content responses. Useful.  
  
On the other hand, if **video and image processing** are more to your liking, [GPUImage 2](https://github.com/BradLarson/GPUImage2), a_"BSD-licensed Swift framework for GPU-accelerated video and image processing"_, now [works inside notebooks](https://github.com/BradLarson/GPUImage2/blob/master/examples/Linux-OpenGL/ImageFilterNotebook.ipynb)... If you prefer using scikit-image for image processing, [this repo](https://github.com/tirthajyoti/Scikit-image-processing) looks like it might contain all the official examples as a set of notebooks...  
  
Something arguably lacking from the Jupyter ecosystem is a core equivalent to the R/Shiny **dashboarding** system. An [early attempt](https://github.com/jupyter/dashboards), the _Jupyter Dashboards Layout Extension_ (and the associated [Jupyter Dashboards Server](https://github.com/jupyter-attic/dashboards_server)) were effectively retired some time ago, and there are examples out there, such as [jupyter-plotly-dash](https://github.com/GibbsConsulting/jupyter-plotly-dash), of wrapping plotly [dash](https://github.com/plotly/dash) apps within Jupyter notebooks. But the latest pretender to this particular throne _\[and a very worthy one...—Ed.\]_ comes in the form of **[Voila](https://github.com/QuantStack/voila)** ([#TJ13](https://github.com/TrackingJupyter/archive/blob/master/TJ13.md#widget-architectures)), which hit version 0.1.0 a couple of weeks ago and is now at 0.1.3. A [post](https://blog.jupyter.org/and-voilà-f6a2c08a4a93) on the official Jupyter Blog gives the highlights: a flexible templating system to produce rich application layouts, a [gridstack](https://github.com/QuantStack/voila-gridstack) included, support for Jupyter interactive widgets, including custom widgets and roundtrips to the kernel, no arbitrary code execution by dashboard consumers, language-agnostic (standard protocols mean you can support any kernel _\[though you probably need the kernel to provide a widgets package to get the full benefit? —Ed.\]_). To seem some examples, here's a [Voila gallery](http://voila-gallery.org/hub/spawn) _"built from Voila, ipywidgets, and The Littlest JupyterHub"_ \[[repo](https://github.com/voila-gallery/gallery/)\].  
  
An [interesting looking project](https://dsf.lacity.org/) from The Data Science Federation, _"a partnership between The City of Los Angeles and Los Angeles area colleges and universities to tackle tough city problems"_ comes in the form of their _Data Science and Predictive Analytics in LA_ initiative. To support the project, it looks like they're running their own JupyterHub: [Citywide Data Science JupyterHub](https://github.com/CityOfLosAngeles/citywide-jupyterhub).  
  
And here's another JupyterHub deployment, [Juno's Personal Data Exploratory](https://exploratory.openhumans.org/), this time from the Open Humans project, which allows you to _"\[e\]xplore, analyze, and donate your data"_ from a range of life and personal data logging sources, including 23andme, Healthkit, Fitbit, Twitter and Spotify \[[about](https://exploratory.openhumans.org/about/)\]. _\[I have to admit this project leaves me cold, even if the intentions are good... I'll be tracking if for all the bad things that might happen: abuse, careless release of personal data, morally dubious exploitation, etc. An interesting complement to this in terms of keeping data local is the [BBC Box](https://www.bbc.co.uk/rd/blog/2019-06-bbc-box-personal-data-privacy), but I'm pretty sure that doesn't run a notebook server or Voila apps...! \[yet?! —metaEd.\] —Ed.\]_

Watching out, as I do, for recently created Jupyter relevant repos on Github _\[Tracking Jupyter is such a glamorous life...—Ed.\]_, I notice this [repo](https://github.com/techtocore/Jupyter-Package-Manager) to support a CERN GSoC project to develop a _Jupyter-Package-Manager_ extension that _"will allow the users to specify python modules (and their respective versions) via a user interface and make them available automatically"_. It'll be interesting to see how this compares to the [nb\_conda](https://github.com/Anaconda-Platform/nb_conda) extension that adds a Conda tab to the Jupyter file browser that allows you to list and manage conda environments and the packages installed in them.

In passing, I also note that if you search on _Jupyter_ using your favourite online bookstore, more and more books with that word in the title are starting to appear... _\[Watching the autocomplete suggestions as you type jupyter into the Youtube searchbox is also interesting...—Ed.\]_

And finally, if you haven't already completed it, here's another chance: [MyBinder user survey](https://docs.google.com/forms/d/e/1FAIpQLSd3fiLCMuQsc48_ga2q_FJFqgFcVUkie7RBex4DtzzOyyNWHg/viewform).

BigCo Jupyter News
------------------

A [post ](https://docs.microsoft.com/en-us/power-platform-release-plan/2019wave2/business-intelligence/planned-features)on the Microsoft Docs site looking at _What's new and planned for business intelligence_ has an _Export AutoML models from Power BI to Jupyter or Azure Notebooks_ feature slated for public availability from October 2019.  
  
Meanwhile, Wolfram Research, publishers of Mathematica, recently [launched](https://blog.stephenwolfram.com/2019/05/launching-today-free-wolfram-engine-for-developers/) a _"Free Wolfram Engine for Developers"__\[which is to say, free with loads of commercial caveats... I'm also guessing this can be accessed as a [Wolfram Language kernel for Jupyter notebooks](https://github.com/WolframResearch/WolframLanguageForJupyter), but deciphering the reasons why it's not actually free, let alone open, means I have better things to do than explore it... —Ed.\]_  
  
Whilst over at Google, the Google [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks/) service (currently in beta) provides _"a managed service offer\[ing\] an integrated JupyterLab environment ..., pre-installed with the latest data science and machine learning frameworks .... Notebooks is integrated \[sic\] with BigQuery, Cloud Dataproc, and Cloud Dataflow";_ the notebooks also support [R kernels](https://cloud.google.com/blog/products/ai-machine-learning/ai-platform-notebooks-now-supports-r-in-beta). As to pricing? There is _"no charge for using Notebooks. You pay only for the cloud resources you use with the Notebooks instance: AI Platform Training, AI Platform Predictions, Compute Engine, BigQuery, and Cloud Storage"_. So two things to note about this: first, the service is referred to as "Notebooks" rather than "Google Notebooks". Second, the business plan: offer a free customised user environment that makes it easy to access other paid for services... _\[If you follow the link to the console and then the Notebooks link, you're blocked by a prompt asking you to enable the Compute Engine API. I'm guessing this could start a meter running when you then launch a notebook, but I'm not going to try... Personally file under: no idea if this is free or not, not sure whether I could start a meter running that will run forever when I can't find how to turn things off... —Ed.\]_  
  
Back in Microsoft land, the strategy is perhaps a different one, encouraging users to use Microsoft's Azure cloud to run self-hosted Jupyter services? For example, on the Microsoft Techcommunity Educator Developer blog, there's a walk-through post on [Deploying BinderHub onto Microsoft Azure](https://techcommunity.microsoft.com/t5/Educator-Developer-Blog/Deploying-BinderHub-onto-Microsoft-Azure/ba-p/687974). This looks like it involved folk at the Alan Turing Institute, who have also shared details of their [BinderHub on Azure](https://github.com/alan-turing-institute/binderhub-deploy) deployment. Nice features include a_"Deploy to Azure"_ button that allows you _"to build a BinderHub \[on Azure\] with a single click (and some form-filling)"_.  
  
On the same blog, there's some "meta-documentation" in the form of a [guided walkthrough](https://techcommunity.microsoft.com/t5/Educator-Developer-Blog/The-Littlest-JupyterHub-on-Azure/ba-p/683833) of how to install The Littlest JupyterHub (TLJH) on Azure. One thing to note about this guide is that it essentially provides a set of structured waypoints into the official TLJH docs. This suggests an interesting consideration when writing docs: _can particular sections in the official docs work also work as standalone, contextualised resources sequenced as part of custom set-up guides, or referred to from FAQs that support other environments built on or using the documented service?_

The University Way...
---------------------

Some interesting repos from Aalto University in Finland on their [AaltoScienceIT](https://github.com/AaltoScienceIT) account: [jupyterhub-aalto](https://github.com/AaltoScienceIT/jupyterhub-aalto), a configuration repo for a teaching related JupyterHub deployment using Kubernetes _"that is tightly integrated into existing Aalto University systems":_

> \[A\]ll users map to institutional users, with institutional groups used to manage instructors for each course; data is stored on institution-provided NFS under real UIDs; courses have shared directories which are mounted for instructors, with an exchange directory mounted for both instructors and students that supports _nbgrader_ use for assignment handling.

The teaching and light computing related JupyterHub runs a container built from [jupyter-aalto-singleuser](https://github.com/AaltoScienceIT/jupyter-aalto-singleuser), the default single-user image. A research focused / heavy computing JupyterHub is built from [triton-jupyterhub](https://github.com/AaltoScienceIT/triton-jupyterhub), which contains configuration details for running JupyterHub on an HPC cluster.  
  
By way of further comparison, [this repo](https://github.com/berkeley-dsep-infra/datahub) contains reproducible configurations for various JupyterHub setups  for use on courses attended by UC Berkeley enrolled students. There are also some hub usage analysis notebooks [here](https://github.com/berkeley-dsep-infra/datahub-usage-analysis). An (undocumented) hub traffic simulator can be found [here](https://github.com/yuvipanda/hubtraf) _\[I wonder if that supercedes this earlier, now archived, [jupyterhub-loadtest](https://github.com/yuvipanda/jupyterhub-loadtest) repo? —Ed.\]_.  
 

Jupyter Notebooks On Windows
----------------------------

I'm not a Windows user, let alone a Windows network administrator, but I wonder if this [recipe](https://www.techcoil.com/blog/how-to-use-nssm-to-setup-jupyter-notebook-as-a-windows-service-running-its-own-python-3-virtual-environment/) for _How to use NSSM to setup Jupyter Notebook as a Windows Service running its own Python 3 virtual environment_ might be a handy way of providing a personal notebook server to administered users? There's a bit of faff getting the initial connection token, but that could be worked around by setting a predefined token and adding it the service startup command?  
  
Perhaps simpler is [this approach](https://yoursdata.net/installing-and-configuring-jupyter-lab-on-windows/) for installing notebooks on Windows as a desktop application using the Chrome browser application mode. The advantage? You get to _"remove all the unnecessary toolbars and UI and gives a feeling of native application or IDE rather than a website running on your browser"_.  
  
Alternatively, here's [a way](https://github.com/hyperspy/start_jupyter_cm) of adding entries to start Jupyter Notebooks from the Windows context menu in Windows file manager context menu (the recipe also works for Gnome...).    
  
And don't forget, you can [also](https://towardsdatascience.com/setting-up-a-data-science-environment-using-windows-subsystem-for-linux-wsl-c4b390803dd) run a notebook server on Windows using WSL...  
  
_(Mac users, if you want a minimal app serving Jupyter Notebooks from the Mac menubar. check out [juno](https://github.com/uetchy/juno).)_  
 

BinderHub, Recontextualised, Several Ways...
--------------------------------------------

Have you ever got fed up with MyBinder rebuilding a Docker image from a Github repo containing lots of complex dependencies when you simply corrected a typo in the README? This [handy trick](https://discourse.jupyter.org/t/tip-embed-custom-github-content-in-a-binder-link-with-nbgitpuller/922) uses [_nbgitpuller_](https://github.com/jupyterhub/nbgitpuller) to pull content from one repository into a container built from another_ \[it be handy to add a tab to handle this to the [nbgitpuller link generator](https://jupyterhub.github.io/nbgitpuller/link) single page web app methinks...? —Ed.\]_. This seems like a really powerful recipe to me _\[I've posted additional thoughts on it [here](https://blog.ouseful.info/2019/05/08/feeding-a-mybinder-container-from-one-github-repository-with-the-contents-of-another/) and [here](https://blog.ouseful.info/2019/06/11/binder-base-boxes-several-ways/)... —Ed.\]_ because it lets you use one rarely changing repo to pre-build a "Binder base box" and a second, rapidly changing repo to provide the content. Because the base box repo doesn't change when you update the content repo, you don't need to rebuild the Binder image each time you want to run the new content.

Using BinderHub to build an environment and execute content within it from the contents of a public repository provides a really powerful approach for testing and sharing notebooks in an interactive and executable way. But here's another way of thinking about BinderHub: as a more general computational environment server. Using it as a Voila dashboard server is one way, but there are others...  
  
By way of example, the [spacy course](https://course.spacy.io/) ([#TJ16](https://github.com/TrackingJupyter/archive/blob/master/TJ16.md#educationally-relevant)) provides a web UI to a set of interactive course materials executed on a MyBinder instance managed using the [Juniper](https://github.com/ines/juniper) JavaScript library. The course can also be "appified" as an electron wrapped application that is also capable of making calls out to a MyBinder code execution environment (see the repo's [electron branch](https://github.com/ines/course-starter-python/tree/electron)). It's perhaps also worth noting that Jupyter Book sites can also be [wrapped](https://blog.ouseful.info/2019/05/19/fragment-jupyter-book-electron-app/) as electron apps capable of executing code against a remote MyBinder launched kernel or a kernel running locally _\[next step is to see if we can put the kernel environment into the electron app too... Or even handle code execution within the electron browser using pyodide, a bit like epiphany.pub does...? —Ed.\]_.  
  
In passing, I've also [experimented](https://blog.ouseful.info/2019/06/11/zero-to-notebook-with-notebook-js-thebelab-inspired-by-nbgrader/) with using [ThebeLab](https://github.com/minrk/thebelab) to provide MyBinder handled code execution support to notebooks uploaded to a single page web app that uses [_notebook.js_](https://github.com/jsvine/notebookjs) to preview a notebook _\[thinks: following epiphany.pub, it'd be really interesting to try to execute the code within the browser using pyodide... —Ed.\]_.

For interactive widget support, [this](http://elc.github.io/posts/embed-interactive-notebooks/) handy looking tutorial shows how to create MyBinder powered interactives in static websites using [nbinteract](https://github.com/SamLau95/nbinteract) powered from Github gists. _\[The examples mostly work, but the image fly in effect used in the post is HORRIBLE... Remember that seasick feeling from watching Prezi presentations? —Ed.\]_  
  
By the by, I also note this electron app —[orca](https://github.com/plotly/orca) —  for generating static images of interactive plotly charts. It's also been Binderised[here](https://github.com/fomightez/orca-plotly-binderized) to provide an environment that lets you _"us\[e\] commands inside a Jupyter environment to save Plotly-generated plots as static images in addition the more typical interactive Plotly plots"_.  
  
In the context of [something else](https://twitter.com/betatim/status/1137001932944498688), @betatim noted recently that _"BinderHub is 'just' a new (and somewhat complex) UI for a JupyterHub"_. So let's explore that a little...  
  
Via a post in the Jupyter discourse community forum, an interesting thread by @YuviPanda on the [idea](https://discourse.jupyter.org/t/would-a-the-littlest-binder-be-useful/1041/13) of _"a littlest Binder"_ that will _"__serve ephemeral sessions (similar to BinderHub) to anyone who joins, but of only one repository you set up"_. This can be implemented as a temporary JupyterHub server serving a container provisioned using _repo2docker_ on a specific repository using the new [repo2dockerspawner](https://github.com/yuvipanda/repo2dockerspawner)_\[I also wondered if this meant that conda environment TLJH spawner could be a thing...—Ed.\]_ The thread hints at an implementation using a [TLJH plugin](http://tljh.jupyter.org/en/latest/contributing/plugins.html),_"the official way to make customized ‘spins’ or ‘stacks’ with TLJH as the base"_ but I couldn't find an associated demo repo anywhere... _\[Hmm... thinks: if I were running a standalone Jupyter notebook server, it would be handy to be able to customise my environment from the same plugin? —Ed.\]_  
  
**TLJH plugins** are new to me, but they look really handy in the way they allow you to _"identify the environment requirements or specify a list of data files to be pre-downloaded in a plugin form, install it into your TLJH setup"_ and provide you with a _"ready to go custom environment"_._\[I wonder if something like [fades](https://github.com/PyAr/fades/), a system for handling and managing virtualenvs, might also be relevant here? Perhaps also the Jupyter-Package-Manager mentioned in the News section above? —Ed.\]_

Doing It From the Command Line...
---------------------------------

A handful of packages have crossed my path over the last few months... _\[You might refer to these as power tools for working from the command line if you're feeling generous, or as simple wrappers for other Jupyter command line tools if you're not... —Ed.\]_  
  
First up, [nbtoolbelt](https://gitlab.tue.nl/jupyter-projects/nbtoolbelt/) ([docs](https://nbtoolbelt.readthedocs.io/en/latest/)) provides a range of wrappers for _nbformat_ and _nbconvert_ commands, as well as some custom functions. The toolbelt commands include:

*   _validate_ for validating notebooks;
*   _head_ for showing the first (last) N lines of the first (last) cell in a notebook;
*   _dump_ for showing cell information (metadata, contents, etc) in a concise (text based) format; _statistics_, to display summary stats generated over a notebook;
*   _view_, to generate and launch an HTML preview of a notebook;
*   _cat_, to concatenate the cells of multiple notebooks into a single notebook;
*   _split_, to split each cell type from one notebook into its own separate notebook;
*   _clean_, to delete specified elements from a notebook;
*   _run_, to execute all code cells in the notebook along with summary statistics; and
*   _punch_, to "punch holes in notebooks" as well as collecting the so-called "chads" (which is to say, the punched out content). Content can be punched out from tagged cells, or from between marker lines. Punched out content can also be replaced with content specified in a config file, or pulled from a second notebook. One particular use case for the punch tool is in creating "cleaned" assessment notebooks for students from "marking guide" annotated parent notebooks. The chad facility can be used to extract student answers from returned assignment notebooks. _\[This differs from the nbgrader approach in which grading is performed over a complete notebook rather than extracted answer cells. —Ed.\]_

Secondly, the [nbless](https://github.com/py4ds/nbless) Python package _"allows you to (de)construct, convert, and execute Jupyter Notebooks in your terminal (e.g. bash, zsh, fish, etc.)"_. It provides six (6) Python functions and shell commands: _nbconv_, for converting notebooks to other formats using pandoc; _nbdeck_, for creating a slidedeck from a notebook; _nbexec_, for running all cells in a notebook and saving the output; _nbuild_, which creates a notebook from .py, .R, .md and .txt source files, adding the contents of .py and .R files to code cells, and of .md and .txt files to markdown cells; _nbless_, which calls _nbuild_ and _nbexec_ to create and execute a notebook; and _nbraze_, which extracts code and markdown files from a notebook into a single code file.   
  
Thirdly, [nbscript](https://github.com/NordicHPC/nbscript) provides a simple tool for running a notebook from the command line with inline arguments. The arguments are transferred into the notebook using environment variables, and accessed inside the notebook from an _nbscript_ object. _nbscript_ also provides a command line command for submit a notebook for execution via a [Slurm](https://slurm.schedmd.com/quickstart.html) workload manager.  
  
Here's another [handy script](http://https://github.com/jvn-io/kernel-run) for running a Jupyter notebook, this time on a remote **Kaggle** kernel (requires a Kaggle account...). With a single command, it allows you to _"upload the Jupyter notebook to a private kernel in your Kaggle account, and launches a browser window so you can start editing/executing the code immediately"_. _\[Hmm... is there something similar for launching MyBinder against a remote repo, I wonder..? —Ed.\]_  
  
Another service that allows you to start and run a simple service from the command line is **Heroku**. Interestingly, the [demo](https://voila-football-pitch-example.herokuapp.com/) for this [voila-interactive-football-pitch](https://github.com/seidlr/voila-interactive-football-pitch) example, which _"combines qgrid and bqplot to create an interactive football pitch widget"_ served by Jupyter Voila, runs on Heroku. The _Procfile_ in the repo \[[docs](https://devcenter.heroku.com/articles/procfile)\] defines the voila start command that runs when the Heroku server is started._ ​\[Thinks: a "voila publish" command, like the "[datasette publish](https://datasette.readthedocs.io/en/stable/publish.html)" command, could be really handy? Further thinks: does Voila also work on Glitch? —Ed.\]_

Computational Publishing and Jupyter Journals As A Service (JJaaS)
------------------------------------------------------------------

_\[Erm...?! —Ed.\]_  
  
Here's the thing... _\[or at least, one of them...—Ed.\]_: the Jupyter notebook approach is great for writing computational recipe books and providing you with a ready stocked kitchen, full of the utensils you need and the ingredients you require, to make the most amazing things.  
  
Via Jason Kottke, I learn of these [Beautiful Maps of the Solar System’s Asteroids and the Topography of Mercury](https://kottke.org/19/06/beautiful-maps-of-the-solar-systems-asteroids-and-the-topography-of-mercury), and they really are beautiful _\[it also looks like further maps and howtos may appear via the [tabletopwhale](http://tabletopwhale.com/) blog...—Ed.\]_. Created by Eleanor Lutz, a [couple](https://github.com/eleanorlutz/topography_atlas_of_space) of [repos](https://github.com/eleanorlutz/asteroids_atlas_of_space) provide a not quite complete computational recipe for creating the maps, but they do go a long way towards it. _\[The recipes also show how sometimes you may want to mix computational automation with some hand-crafting in a user driven environment; the robots are not going to have it all their own way! —Ed.\]_ Some of the source image data files are linked and need to be downloaded, but note that a couple of them come in at several gigabytes... _\[I made a start on a Binder box that will run the scripts but haven't had time to check the notebooks are completely runnable within it. For example, I did note that some files fail to write because necessary directory paths don't exist... —Ed.\]_ What I can imagine, as a well as a slim coffee table book of the maps themselves, is a more complete computational recipe digital coffee table book that recreates them in computationally generated, illustrated fashion, each step of the way.  
  
Perhaps more to the point, recipes like the above provide an example of how investing in computational publishing recipes means that once you've done the hard work of automating the production of one particular asset, you can use it to generate variations on the same theme by switching the data or tweaking the algorithm...  
  
Providing platforms that support the creation of rich media assets by computational means is one part of the publishing workflow, but providing trusted repositories for sharing executable, literate computational narratives is another.  
  
From last year, I note that at least one of the IEEE journals, the _IEEE Journal of Oceanic Engineering_, have started to explore how reproducible and interactive papers might work in the IEEE publishing context. A traditionally presented[editorial](https://ieeexplore.ieee.org/document/8410389) from July 2018 looks as if it might have been generated from a computational source [equivalent](https://codeocean.com/capsule/9155944/tree/v1) hosted and runnable on CodeOcean. Also from the looks of it, that may just have been a one off experiment; so if you want to a submission into the IEEE publication route from a literate computation environment in the meantime, you might have to stick with using something like this [jupyter-ieee-paper](https://github.com/org-arl/jupyter-ieee-paper) template.  
  
A new project, **[Neurolibre](https://conp-pcno.github.io/)**, published _\[I think? —Ed.\]_ under the auspices of the Canadian Open Neuroscience Platform (CONP),provides a _"curated repository of interactive neuroscience notebooks"_. It seems like this could provide an interesting addition to the current "grey" scientific publishing environment, in neuroscience at least. Backed by a [platform provided BinderHub service](https://binder.conp.cloud/) \[[deployment repo](https://github.com/neurolibre/neurolibre-binderhub)\], it allows two forms of submission: tutorial notebooks related to a workshop in the neuroscience field, and companion notebooks for articles posted as preprints in the neuroscience field. According to the submission guidance:

> \[s\]ubmissions are not reviewed in the sense of a traditional peer-reviewed publication, but notebooks do undergo a technical review. The NeuroLibre team checks that the notebooks fit one of the two tracks above, run correctly, and that the text and code are readable. We also check how much compute time and data storage are required. NeuroLibre commits to provide computational resources for free, yet this investment must benefit substantially the Open NeuroScience community.

Loosely related, this post on the _Journal of Open Source Software_ Blog — [Cost models for running an online open journal](http://blog.joss.theoj.org/2019/06/cost-models-for-running-an-online-open-journal) — gives an indication of how much it costs to run just such an open journal before you factor in any BinderHub or BinderHub Federation costs...  
  
The _Neurolibre_ approach looks like it could provide a semi-formal way of sharing runnable notebook appendices for preprints, as well as resources for tutorials. But perhaps what's lacking, at the moment at least, is a formal way of identifying resources.  
  
A recent update to the MyBinder user interface adds support for a **Zenodo DOI** (digital object identifier) provider _\[DOIs are great because they're persistent, unique and resolvable... —Ed.\],_ about which an official blog post looks like it's on its way... _\[If you follow the Jupyter discourse forums closely, you'd know that already...;-) —Ed.\]_. What this means is that MyBinder can now accept a Zenodo DOI that points to an archived Github repository and build an environment from it.  
  
Zenodo DOIs such as _10.5281/zenodo.3242074_ map onto a Binderised URL of the form: _https://mybinder.org/v2/zenodo/10.5281/zenodo.3242074/_ so it's easy enough to roll your own links'n'badges. The Binder provider is not surprising handled by _repo2docker_, I'm guessing using [this](https://github.com/jupyter/repo2docker/pull/693) Zenodo provider PR, via [this](https://github.com/jupyterhub/binderhub/pull/870) BinderHub PR.  
  
It also looks as if the _repo2docker_ DOI provisioning may be[in the process](https://github.com/jupyter/repo2docker/pull/704) of being generalised.  
 

A Plotting Miscellany
---------------------

Tracking plotting and charting frameworks is a bit like playing whack-a-mole: early movers such as IBM's [Brunel](https://github.com/Brunel-Visualization/Brunel) visualisation toolkit for generating_"interactive data visualizations based on tabular data"_ seem to have been deprecated _\[unless it's that stable it doesn't really need maintaining any more?! —Ed.\]_ but then another toolkit or wrapper comes along... So here are some charting tools and toolkits I've spotted since the previous round-up way back in [#TJ5](https://github.com/TrackingJupyter/archive/blob/master/TJ5.md#charting)...

*   [jupyter-matplotlib](https://github.com/matplotlib/jupyter-matplotlib) _\[which looks to have received quite a few commits recently... —Ed.\]_ _"leverag\[es\] the Jupyter interactive widgets framework to enable the interactive features of matplotlib in Jupyter notebooks and Jupyterlab"_, also _"\[casting\] the figure canvas element as a Jupyter interactive widget which can be positioned in interactive widget layouts"_;
*   [seaborn](https://seaborn.pydata.org/) also builds on matplotlib, prettifying matplotlib charts simply by importing the package into a notebook. It also provides a wide range of statistical chart types and tight integration with pandas ([example](https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html));
*   [plotly-express](https://medium.com/@plotlygraphs/introducing-plotly-express-808df010143d) \[[repo](https://github.com/plotly/plotly_express)\], _"a new high-level Python visualization library \[that provides a\] wrapper for Plotly.py that exposes a simple syntax for complex charts. Inspired by Seaborn and ggplot2, it was specifically designed to have a terse, consistent and easy-to-learn API"_;
*   [cufflinks](https://github.com/santosjorge/cufflinks) is library that _"__binds the power of plotly with the flexibility of pandas for easy plotting"_; it's not so much documented as exampled... _\[Given I'm not that up on plotly (or pandas plotting) syntax, I can't really tell offhand if it makes things easier or not! —Ed.\]__;_
*   [PlotPlaygound](https://github.com/simon-ritchie/plot_playground), a Jupyter plotting library with support for _pandas_ dataframes: under active development and with a slop plot option._ \[I do like a good slope chart.... Here's [another example](https://github.com/pascal-schetelat/Slope)... —Ed.\]_
*   [pygal](https://github.com/Kozea/pygal) \[[docs](http://www.pygal.org)\], a _"dynamic SVG charting library written in python"_ supported a wide range of standard chart types, but also seems to have had it's day...;
*   [iplotter](https://github.com/niloch/iplotter) — JavaScript charting in IPython/Jupyter notebooks _\[old, but another one for the completionists' lists... —Ed.\]_

For a quick review of some of the other frameworks around, [this notebook](https://github.com/claresloggett/demo_visualisation_python/blob/master/Demo_Visualisation.ipynb) has demos of charts created using Matplotlib, Seaborn, Altair, Plotly, Bokeh and Holoviews, although note that things may have moved on since! For a Holoviews tutorial from JupyterCon 2017, see [here](https://github.com/ioam/jupytercon2017-holoviews-tutorial), with the same caveat applied... For a review of some techniques for creating interactive visualisations using linked charts, see this post on [Interactive Visualization Combo with Python](https://towardsdatascience.com/jupyter-superpower-interactive-visualization-combo-with-python-ffc0adb37b7b) and its [associated repo](https://github.com/noklam/Gallery). And again...  
  
Adding to the Vega/VegaLite tools mentioned in the [#TJ5 review](https://github.com/TrackingJupyter/archive/blob/master/TJ5.md#charting), [ipyvega](https://github.com/vega/ipyvega) provides an IPython/Jupyter notebook module for Vega and Vega-Lite that allows notebooks with embedded visualisations to be viewed on GitHub and _nbviewer_. (The extension is only required for Jupyter notebooks: JupyterLab comes with built-in support for Vega and Vega-Lite.)  
  
If you want to work with Vega / Vega-Lite from Clojure, [this package](https://github.com/metasoarous/oz) may be more to your taste.

For 3D CAD models, last mentioned in [#TJ3](https://github.com/TrackingJupyter/archive/blob/master/TJ3.md#notebooks-in-research), [ViewSCAD](https://github.com/nickc92/ViewSCAD) provides a _"__Jupyter renderer for the OpenSCAD and [SolidPython](https://solidpython.readthedocs.io/en/latest/#example-code) Constructive Solid Geometry languages"_.  
  
I'm also reminded of [K3D-jupyter](https://github.com/K3D-tools/K3D-jupyter) for creating 3D plots backed by WebGL, last mentioned back in [#TJ6](https://github.com/TrackingJupyter/archive/blob/master/TJ6.md#jupyter-goes-3d); it seems to have been receiving regular commits since then, so it may be one to have another play with to see what new goodies it supports?  
  
Sometimes you just want a plotting packages that does one thing, but does it well.  
  
If it's Sankey diagrams you want, [floweaver](https://github.com/ricklupton/floweaver) generalises over the _pandas_ friendly _ipysankeywidget_ ([#TJ11](https://github.com/TrackingJupyter/archive/blob/master/TJ11.md#notebooks-and-extensions)), as well as requiring it in order to render diagrams, to support a more flexible _\[but harder to use? —Ed.\]_ flow based visualisation model based on the notions of _ProcessGroups_, _Waypoints_, _Partitions_, and _Bundles_ _\[no, me neither...—Ed.\]_. Your best bet is to probably skim through the [docs](https://floweaver.readthedocs.io/en/latest/index.html) and see if it does what you want, or read the authors' [paper](https://www.repository.cam.ac.uk/handle/1810/265367) on _Hybrid Sankey Diagrams_...  
  
On the other hand, if it's missing data you want to track down, [missingno](https://github.com/ResidentMario/missingno) may be of use, _"a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset"_.  
  
The new looking [pytgraph](https://github.com/intv0id/pytgraph) package provides a 3D graph (in the sense of "network") visualization jupyter widget for [tgraph](https://github.com/intv0id/tgraph), a typescript library for drawing 3D graphs which _"aims to draw an interactive and modular representation of information networks"_, apparently. _\[This seems to be based on jgraph, which you may remember from the [#TJ15](https://github.com/TrackingJupyter/archive/blob/master/TJ15.md#visualising-graphs) Visualising Graphs roundup... —Ed.\]_

Riffing More Widely Around the Idea of "Books"
----------------------------------------------

Whilst I've been having a lot of fun with Jupyter Book, it's worth remembering that this provides just one take on generating chapterised online books from a set of notebooks.  
  
At heart, Jupyter Book is a **Jekyll** powered publishing system. But several other Jekyll based notebook publishing packages are out there, including _nbjekyll_ ([#TJ10](https://github.com/TrackingJupyter/archive/blob/master/TJ10.md#publishing-notebooks)) and[JekyllNB](https://github.com/klane/jekyllnb). The latter extends _nbconvert_ to support the creation of markdown files from notebooks, that you can then publish as a Jekyll site. _\[I'm not sure if things like this, and the Sphinx tools mentioned in #TJ5, #TJ6 and #TJ11 are useful now as anything other than indicators of what Jupytext and pandoc might be able to, or likely to, do if they don't already? —Ed.\]_  
In that spirit of looking at legacy, perhaps even deprecated, tools to see what routes ended up not being travelled, [stitch](https://pystitch.github.io/) and [knitpy](https://github.com/jankatins/knitpy/) are _\[were?! —Ed.\]_ two deprecated packages that sought to make like _knitr_ does for R/Rmd, but for Python.  
  
Another stalled(?) approach, this time from @takluyver, was [Bookbook](https://github.com/takluyver/bookbook), a set of _"\[t\]ools to use a collection of notebooks as 'chapters'"_ that would _"convert a set of notebooks in a directory to HTML or PDF, preserving cross references within and between notebooks"_. From the same stable, [cite2c](https://github.com/takluyver/cite2c) provides citation support in Jupyter Notebooks via a toolbar launched UI for finding and inserting citations from a Zotero library into Markdown cells. The citation data is stored in notebook metadata, referenced by an ID, and rendered inline as well as to a bibliography, using [citeproc-js](https://github.com/Juris-M/citeproc-js), a JavaScript implementation of the [Citation Style Language (CSL)](https://citationstyles.org/).  
  
Perhaps in a similar vein, [Makebook](https://github.com/ProfessorKazarinoff/makebook) is a still-early-days Python project that makes a LaTex "book" from a set of Jupyter notebooks and markdown files.

And Finally...
--------------

As ever, I rarely get round to doing things properly, so it's handy when I can crib from other people who do _\[which is: All. The. Time. —Ed.\]_. In this case, a papermilled Jupyter notebook \[[repo](https://github.com/choldgraf/jupyter-activity-snapshot)\] for grabbing a snapshot of recent Jupyter activity in a variety of locations, courtesy of Chris Holdgraf...
