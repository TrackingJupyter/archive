Welcome to this eighteenth edition of the _Tracking Jupyter_ newsletter (#TJ18).  
  
The news is a bit bleurgghhy this week: a couple of weeks away, hols'n'poorly, a backlog before that etc etc. There was no normal service that can be resumed in the next issue anyway, so it is what it is, and will be what it will be... And it may not be on Fridays...

News
----

I had a wonderful time at the Bloomberg supported _nbgrader_ Jupyter Community Workshop in Edinburgh last week _\[thanks to James and the Noteable/Edina team for putting it together —Ed.\]_. The Jupyter community is a really welcoming one, so if you get a chance to attend an event, I highly recommend it. The latest workshop to be announced is the [Jupyter Community Workshop: South America](https://blog.jupyter.org/jupyter-community-workshop-south-america-d8e482652952) in Córdoba, Argentina, from Jun 22nd to Jun 23rd, 2019, but I suspect the sign-up deadline will have passed by the time this newsletter is finally posted...  
  
...on the other hand, if you're anywhere near Amsterdam on June 13th, the third [Jupyter Amsterdam meetup](https://www.meetup.com/Jupyter-Amsterdam/events/261614525/) takes place at _SURFsara_ from 5.15pm-8.15pm.  
  
For virtual meetups, the next **Jupyter Community Call** is on Tuesday, June 25th, 2019 at 9am PST. Help set the agenda [here](https://discourse.jupyter.org/t/jupyter-community-calls/668).  
  
Also probably too late for you attend (June 4th), but worth a mention as an example of a sort of event you might try persuade _your_ Library to run, a day long training event on ["](https://www.eventbrite.co.uk/e/future-proofing-your-research-moving-towards-open-reproducible-research-tickets-60575376582)[Future-proofing your research: Moving Towards Open & Reproducible Research"](https://www.eventbrite.co.uk/e/future-proofing-your-research-moving-towards-open-reproducible-research-tickets-60575376582) organised as a _"collaboration between open research groups at Lancaster and Manchester, and Lancaster University Library"_. Not just for early stage researchers, _"\[i\]t is also intended that experienced academics who supervise researchers and PhD students could gain insights into the latest open research practices and be better equipped to support their staff and students in these endeavours"_.  
  
nbgallery looks like it may be getting a [Python API](https://github.com/nbgallery/nbgallery-api-python)_\[which should make it a lot easier to handle bulk uploads compared to my own [Selenium bulk uploader hack](https://blog.ouseful.info/2019/01/21/bulk-notebook-uploads-to-nbgallery-using-selenium/)...—Ed.\]_.  
  
The Jupyter-sphinx extension for producing documentation from Jupyter notebooks [appears](https://blog.jupyter.org/integrating-output-in-documentation-with-jupyter-sphinx-ecf569ddab85) to have been rewritten, now offering improved widget support. _\[I'm not sure: a) how this compares to Jupyter Book; b) why it's useful to show widgets if they're not connected to code/a kernel underneath? What am I missing?! —Ed.\]_ Meanwhile, in JupyterLab land, it looks like folk have been working on improving [support for printing](https://github.com/jupyterlab/jupyterlab/pull/5850).  
  
SevenBridges, providers of _"\[a\]ctionable informatics for biomedical research"_ recently announced the release of [Data Cruncher](https://www.sevenbridges.com/data-cruncher-interactive-analysis/), _"an interactive analysis tool available on the Seven Bridges Platform, Cancer Genomics Cloud, and Cavatica"_. The _Data Cruncher_ tool appears to be JupyterLab _\[I'm not sure if it's customised with particular tools/extensions pre-installed, integrated with particular datastores, etc, which I think will start to become a point of differentiation... —Ed.\]._  
  
Also on the genomics front, a biorxiv [preprint](https://www.biorxiv.org/content/10.1101/614222v1) on _CoolBox: a \[sic\] interactive genomic data explorer for Jupyter Notebook_, which the keenest of readers may recall from [#TJ16](https://github.com/TrackingJupyter/archive/blob/master/TJ16.md).  
  
Meanwhile, a [post](https://discourse.jupyter.org/t/ann-a-new-binder-gallery/1204) on the Jupyter community discourse site announced a new [GESIS Notebooks Binder Gallery](https://notebooks.gesis.org/gallery/) that includes a dynamically updated _"__Popular Repositories"_ table updated from recent launches on the GESIS binder.  
  
I think I may have missed this at the time it was released, but Microsoft'sAzure DevOps Services / Server marketplace features a [Jupyter Notebook Renderer](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.ipynb-renderer) _\[that, erm, renders notebooks somewhere?!  —Ed.\]_.  
  
In [#TJ17](https://github.com/TrackingJupyter/archive/blob/master/TJ17.md#getting-animated), I reviewed various approaches for creating animations within Jupyter notebooks. Live chart updating is something in particular I think we'll start to see more of. For example, [Live Loss Plot](https://github.com/stared/livelossplot) is a new _"live training loss plot in Jupyter Notebook for Keras, PyTorch and other frameworks"_; for a more heavyweight approach, Microsoft Research have released [TensorWatch](https://github.com/microsoft/tensorwatch), a debugging, monitoring and visualization notebook tool for deep learning and reinforcement learning.  
  
Something else I think we'll see more of are exploratory data analysis toolkits. For example, [edaviz](https://github.com/tkrabel/edaviz) provides a _"Python library for Exploratory Data Analysis and Visualization in Jupyter Notebook or Jupyter Lab"_ ([video demo](https://www.youtube.com/watch?v=eYEeYv11YrQ)). _\[It might be interesting to see a walkthrough of this using Jupyter Graffiti...I also wonder what Tukey would have made of it! —Ed.\]_ If you simply want to compare rankings, the [notebook widgetised](http://lineup.js.org/integrations/jupyter) lineup.js package may be enough for your needs...  
  
For Samsung Galaxy users, the [_Linux on DeX_](https://www.linuxondex.com) app creates secure container within the app, inside of which you can run an Ubuntu Linux image. Which means you [should be](https://towardsdatascience.com/pydata-stack-in-your-pocket-literally-73662c20d18e) able to run a notebook server inside it, right?  
  
One of the problems of supporting reproducibility in notebooks is that notebooks don't currently describe their own build dependencies. A recent metadata initiative, [SelfContainedJupyterNotebooks](https://github.com/gclouduniverse/SelfContainedJupyterNotebooks), looks like it could improve that with a mooted extension that will help _"embed environment information into a notebook and parse the information out from there"_. _\[Just as long as it can also be respected by Jupytext etc... —Ed.\]_  
  
Binderhub is a great tool for building and launching custom environments from a specification provided in a Gthub repo, but it's can be a bit heavyweight on the install front _\[kubernetes inside, etc. For a workshopped version of the zero2jupyterhub process, see this presentation on[ "Scalable JupyterHub deployments for Education, Research, Analytics"](https://docs.google.com/presentation/d/1ELYepgptS7LcpBwjrotPRcQENr_WlxX0eQaBvzZonxs/edit#slide=id.p) —Ed.\]._ How much easier it would be it there were a "Littlest Binderhub" route? Courtesy of Yuvi Panda, the JupyterHub [repo2dockerspawner](https://github.com/yuvipanda/repo2dockerspawner) makes _repo2docker_, the engine that underpins the Binderhub container builder, available as a JupyterHub spawner. _\[Which means you can build, and launch, a notebook environment from a Github repo using your own JupyterHub server, even a littlest one... —Ed.\]_  
  
If running RStudio alongside Jupyter notebooks is your thing, the [j](https://github.com/jupyterhub/jupyter-rsession-proxy)[upyter-rsession-proxy](https://github.com/jupyterhub/jupyter-rsession-proxy) builds on the _jupyter-server-proxy_ to provide an easy way of launching RStudio and a Shiny application from Jupyter notebooks / JupyterLab.  
  
This week sees the Jupyter Community Workshop on [Dashboarding with Project Jupyter](https://blog.jupyter.org/jupyter-community-workshop-dashboarding-with-project-jupyter-b0e421bdf164) taking place in Paris. This newsletter will probably just miss the cut on any outputs from that event, but here's a handy _[dashboards](https://github.com/nbgallery/dashboards)_ repo from the _nbgallery_ folk that collates _"various __notes and experiments in Jupyter dashboarding__"_. As an example of the sort of thing you can do with dashboards in a Jupyter context, here's an [example](https://github.com/pyviz-demos/glaciers) of a dashboard that lets you cross-filtering a set of reports _"on all global glaciers using datashader and holoviews"_ _\[the Binder link paths seem broken to me but if you poke a round you should be able to fix 'em..—Ed.\]_.  
  
Something I've noticed from social media searches around the whole "jupyter" thang is the growing number of non-English language references to it_ \[something else I've noticed in general on the web is how rarely "foreign language" pages turn up most of the time, which makes me wonder what I'm missing...—Ed.\]_. By way of an example, here's an interesting looking course in [French](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx/index.html); but perhaps more importantly, getting machinery in place to support [Jupyter docs translation](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/translations.html) to other languages is a good call, I think...  
  
Also of note, there's a wealth of NLP packages out there, but the models and examples often seem to be based around English language texts. So it's good to see this list of [multilingual NLP](https://github.com/multilingual-dh/nlp-resources) resources _"and pointers to language-specific directories of resources, ... originally created for a presentation at UCLA on teaching multilingual digital humanities, on May 15, 2019"_.  
  
If you've ever used _nbgitpuller_, you're probably familiar with some of the fun phrases _\["reticulating splines", apparently! —Ed.\]_ that stream by whilst the repo synchs. Binder waits are often longer, _\[running into days, it feels like, although the stats don't lie apparently...—Ed.\]_, so if you're feeling witty, why not contribute some pithy phrases to this[discourse thread](https://discourse.jupyter.org/t/binder-loading-messages-how-witty-are-you/1241) to help keep folk entertained as a Binder starts.

Chris Holdgraf has been on the evangelical presentation trail again, most recently at _CSVconf_ on _Open infrastructure for Open Science - How Binder powers an open stack in the cloud_ \[[slides](https://speakerdeck.com/choldgraf/open-infrastructure-for-open-science-how-binder-powers-an-open-stack-in-the-cloud)\] and at the Symposium on Data Science and Statistics (SDSS2019) on _Open Infrastructure in the Cloud with JupyterHub_ \[[slides](https://speakerdeck.com/choldgraf/open-infrastructure-in-the-cloud-with-jupyterhub)\].  
  
And finally, for your listening pleasure, a _This Week in Machine Learning and AI_ podcast on [Librosa: Audio and Music Processing in Python with Brian McFee](https://twimlai.com/twiml-talk-263-librosa-audio-and-music-processing-in-python-with-brian-mcfee/) that includes a discussion of Jupyter notebook workflows. Jupyter minded roboticists also get a listen in with this episode on [Using ROS on Jupyter notebooks with Wolf Vollprecht](http://www.theconstructsim.com/ros-jupyter-notebooks-wolf-vollprecht/) on the _ROS Developers' Podcast (RDP)_.

Filling in the Gaps...
----------------------

Picking up on the tools for annotating training sets I mentioned in [#TJ17](https://github.com/TrackingJupyter/archive/blob/master/TJ17.md#training-data-annotation-tagging-extensions), here's another: [Jupyanno](https://github.com/chestrays/jupyanno). The demo is a chest X-Ray tagging task and there's a really nice dashboard display that I don't understand at all. The Binder example works, but not like the example video. _\[Maintenance of the repo looks to have stalled, unfortunately? —Ed.\]_  
 

From the Twitterz:
------------------

A senior lecturer [hoped](https://twitter.com/lexnederbragt/status/1128721679583199239): _"\[j\]ust submitted a grant proposal (internal funding @UniOslo) aiming to integrate Jupyter @ProjectJupyter notebooks with our local Canvas LMS. Fingers crossed that we’ll be funded!"_  
  
A staff scientist [opined](https://twitter.com/eglerean/status/1126102359355142145): _"\[w\]__e were brainstorming just yesterday that one approach would be to let reviewers and other scientists run their algos on our @AaltoUniversity jupyterhub system, so that data and processing could stay local. Just an idea for now, but maybe one day...?__"_  
  
An edtech lady leader [imagined](https://twitter.com/ammienoot/status/1126413530205446144): _"\[s\]__o now I'm dreaming of a world where the HTML content authoring functionality in any VLE was essentially like a notebook__"._  
  
A CEO [posed](https://twitter.com/tebeka/status/1135832848848629761): "#Jupyter notebooks are the new #Excel Discuss..."  
  
A digital archaeologist [lamented](https://twitter.com/electricarchaeo/status/1129930357095239681):_"I learn more from a jupyter notebook or similar than any academic paper when it comes to anything vaguely digital. I get so frustrated otherwise. I wish dh papers came with working code examples, walkthroughs. Y'know, the whole literate programming thing"_.

Meanwhile, a co-creator of Django [chastised himself](https://twitter.com/simonw/status/1134486514337865728) with the thought that: _"\[h\]onestly the Jupyter notebook data ecosystem is so powerful and productive these days it's worth brushing up on Python just for that - I only started using it two years ago and I've been kicking myself for not getting into it sooner. Perfect tool for ad-hoc analysis"_ before [reflecting](https://twitter.com/simonw/status/1134486904093544452): _"\[the b\]est thing about Jupyter is that you muck around for a few hours figuring out how to do X... and then six months later when you need to do X again your previous notebook shows you exactly how to do it! Every project creates solid documentation as a side-effect of using the tool"_.

As well as sharing the love on social media, here's an example of something I can see happening more and more: folk sharing DIY examples of their research / analysis services in the form of PR style feel good stories with try-it-yourself notebooks. For example, from the _Transformation Bioinformatics Team_ at the Australian government's CSIRO research agency: [Jupyter notebook powers reproducible and interoperable genomic research](https://medium.com/@TransBioinf/jupyter-notebook-powers-reproducible-and-interoperable-genomic-research-2ad2b4b3f2b2). _\[Just imagine: "technical PR" folk who can figure out how to create nice runnable examples from larger scale (open) research projects to support their news stories...—Ed.\]_ The same trick works for sales. For example: [Analyze traffic data from the city of San Francisco](https://developer.ibm.com/patterns/analyze-san-francisco-traffic-data-with-ibm-pixiedust-and-data-science-experience/)_(IBM Watson Studio marketing pitch)_.  
  
And finally, I was going to suggest this a possibly good feed to follow, but there isn't one, so this may be the only mention I ever make of the misnamed Berkeley CTO Resource Center "blog" _\[blog implies feed, right? And yes, I am an [RSS fan](https://psychemedia.github.io/original-ouseful-blog-archive/pages/010271.html)... —Ed.\]_: what looks like the first in a series of a posts on [Jupyter at Berkeley](https://cto.berkeley.edu/blog/jupyterhub-berkeley).

Notebook Recipes and Examples
-----------------------------

An interesting snippet: [video frame tagging](https://github.com/pamruta/Wild-Life/blob/master/video-tagger.ipynb) using Keras models and Youtube videos. If you want to grab Youtube videos via an API, this [youtube-video-search-on-jupyter](https://github.com/simplestreet/youtube-video-search-on-jupyter) package handles that for you, and plays nicely with notebooks too _\[although it requires a Youtube API key... Sigh... I remember the good old days back when the web was open... —Ed.\]_  
  
A nice notebook styled tutorial on [mixed models](https://web.stanford.edu/class/psych252/section/Mixed_models_tutorial.html) _\[I'd share OU notebooks, too, but for some reason we don't share things so openly now we predominantly produce digital warez...—Ed.\]_.  
  
Purdy.... [ridge map plots](https://github.com/ColCarroll/ridge_map) package that lets you _"c__hoose a location, get an elevation map, and tinker with it to make something beautiful..."__\[Think the hand-drawn maps in the front of a book like Lord of the Rings.. —Ed.\] _Someone had a play [here](http://www.acgeospatial.co.uk/ridge-map-plots-using-python/).  
  
Artistic in another way, this technique for co-opting 3D visualisation techniques, [Procedural Pointillism by Probabilistic Processing of Particle Positions in Python](https://quorumetrix.blogspot.com/2019/05/scalable-pointillism-from-raster-images.html), proposes _"a method to approximate a 2D or 3D image as an array of points, so that they can be scaled up and visualized in a 3D modeling environment";_ an associated notebook can be found [here](https://github.com/tsloan1377/Misc_dataViz/blob/master/Pointilism.ipynb). The same repo has some other nice visualisations, such as this [shapefile to datashader](https://github.com/tsloan1377/Misc_dataViz/blob/master/shapefile_to_datashader.ipynb) example notebook.   
  
_\[By the by, I note that Uber's [long teased](https://github.com/keplergl/kepler.gl/issues/331) kepler.gl notebook integration still doesn't appear to have been formally announced/released, but it does look like there have been a couple of related PRs__: [Add Jupyter widget - JS Module](https://github.com/uber/deck.gl/pull/3035) and  [Add Jupyter widget to pydeck library](https://github.com/uber/deck.gl/pull/3050)?—Ed.\]_  
 

Imaging, the First...
---------------------

It's been some time since I did a round of imaging tools, so here are some old ones I haven't got round to posting before, and some ones that are also new to me... There's quite a lot to catch up on, so I'll try to split things into sensible parts...  
  
From my _previously unshared_ link archive, [ITK](https://itk.org/) is medical image Insight Segmentation and Registration Toolkit from the US National Library of Medicine. It's supported by [itk-jupyter-widget](https://github.com/InsightSoftwareConsortium/itk-jupyter-widgets), interactive Jupyter widgets based on _ipywidgets_ that support visualisation and analysis of images in 2D and 3D designed using ITK _"as well as other spatial analysis tools in the scientific Python ecosystem"_. This is built in part on the [VTK.js](https://kitware.github.io/vtk-js/index.html) _"scientific visualization in your browser"_ and [itk.js](https://github.com/InsightSoftwareConsortium/itk-js) _"high-performance spatial analysis"_ JavaScript libraries.  
  
If it's neuroimaging data you want to visualise, you could also try [niwidgets](https://github.com/nipy/niwidgets) _\[I had most success with the demo\_update__.ipynb__ notebook...—Ed.\]_. This looks like it uses [nibabel](http://nipy.org/nibabel/) under the hood, which provides provides read/write access to a wide range of medical and neuroimaging file formats, so it might be quite a handy general purpose tool?

Way back when in [#TJ4](https://github.com/TrackingJupyter/archive/blob/master/TJ4.md#notebooks-in-action), I mentioned some [demo notebooks](https://github.com/Slicer/SlicerNotebooks) for working with 3D Slicer, a 3D medical imaging package; I poked around a little more at the time and also found a Jupyter Slicer kernel available: [SlicerJupyter](https://github.com/Slicer/SlicerJupyter). So if you want to access Slicer model views from an arbitrary web page using something like _nteract_, you can...  
  
If you fancy a weekend project, [nyroglancer](https://github.com/funkey/nyroglancer) is an old-but-new-to-me extension _\[or it was when I first spotted this for Tracking Jupyter several months ago..—Ed.\]_ that allows you to visualise large _numpy_ arrays using Google's [_neuroglancer_](https://github.com/google/neuroglancer). It's lacking the dependency files it would need to run in MyBinder and there's no demo notebook. _\[If neuroglancer is still a thing, I'd quite like to be able to see a demo of it via MyBinder...—Ed.\]_

Who Goes There?
---------------

If you need OAuth permissions to access things from Jupyter notebooks, the [ipyauth](https://gitlab.com/oscar6echo/ipyauth)_ipywidget_ may help ([article](https://medium.com/@olivier.borderies/oauth2-from-inside-a-jupyter-notebook-5f5e61ec5d38)). It allows you to authenticate to a third party service, such as Google using OAuth in a really clean way. The code is, of course, available in the repo, if you want to check it's not stealing secrets before you give it a spin. Rick Wagner [comments](https://twitter.com/rpwagner/status/1126577871592366080) "\[t\]_hat will work for some implementations of OAuth, but not all. Depends on the type of clients supported. The issue is whether the server doing the auth (not the JupyterHub one) supports pure JS clients, or needs a confidential client on the JH server" \[at some point, I am going to have to get my head around auth...—Ed.\]_  
  
If authenticated identity management is an issue, it looks like there may be an [OpenID Connect (OIDC) authenticator](https://github.com/datalayer/jupyterhub-oidc) for JupyterHub along any time now... _\[Though beyond my ken, it seems that OpenID Connect adds "__a simple identity layer on top of the OAuth 2.0 protocol__". Am I right in thinking the[ LTI authenticator](https://github.com/jupyterhub/ltiauthenticator) and the [LDAP authenticator](https://github.com/jupyterhub/ldapauthenticator) also help out with identity? —Ed.\] _  
  
At a slightly lower level, this [sshapiauthenticator](https://github.com/NERSC/sshapiauthenticator) _"enables SSHAuth Authentication for Jupyterhub"_ through the acquisition of _"a private SSH key from a SSH Auth API service"_. The same team at the National Energy Research Scientific Computing Center (NERSC) also publish a [JupyterHub sshspawner](https://github.com/NERSC/SSHSpawner) that enables JupyterHub _"to spawn single-user notebook servers on remote hosts over SSH"_.  
  
It seems this appeared way back in JupyterHub 0,7, but it's new to me: [JupyterHub managed services](https://jupyterhub.readthedocs.io/en/stable/reference/services.html), which among other things look like they may provide a way of using JupyterHub as a single-sign on auth manager. Services come in two flavours:_hub-managed services_, which are managed by JupyterHub and operate as local subprocess of the Hub; and_ externally-managed services_, which run their own web server and communicate operation instructions via a JupyterHub’s API. Externally-managed services use a unique API token to identify the originating service or user and authenticate each API request. As an example, _nbviewer_ can be run as an [authenticated JupyterHub service](https://github.com/jupyter/nbviewer#securing-the-notebook-viewer) in either hub managed or externally managed form. But perhaps more interestingly, this [recipe](https://gitlab.com/DentonGentry/discourse-gitlab-sso) demonstrates a Jupyter managed service that _"__provide\[s\] single-sign-on support for a Discourse forum associated with a JupyterHub instance, allowing users visiting the forum for the first time to have their identity and profile be automatically populated from information in JupyterHub and Gitlab"_. _\[Anyone got other examples of using JupyterHub to manage third party authenticated service access? —Ed.\]_

Operating In the Wild...
------------------------

How much things cost is often under-reported, so here's another occasional take on Jupyter economics, this time from the Pangeo folk: [Pangeo and Kubernetes, Part 1: Understanding costs](https://medium.com/pangeo/pangeo-cloud-costs-part1-f89842da411d). Originally supported by an NSF EarthCube award of _"about $100,000 of compute credits over three years with Google Cloud Platform",_ from one of the charts, current daily costs seem to be about $200 per day. As well as running the pangeo Binder instance and covering storage costs (_"$35/day for 56 TB"_), the team also support the [Pangeo-Cloud-Federation](https://github.com/pangeo-data/pangeo-cloud-federation), Pangeo clusters organized by research area (current cluster names, presumably self-describing of the related topic area, are _ocean_, _hydro_, _nasa_ and _icesat_). A back of the envelope sketch suggests that with a single server running persistent services at $60 per month, Jupyter pool costs of $21 per user per week on a 20 hrs per user per week basis, and another $100-30 per user per week for running large Dask jobs, a research group of 8 racks up about $500/month in compute costs.  
  
For the dev-ops folk amongst you, the [pangeo-cloud-federation](https://github.com/pangeo-data/pangeo-cloud-federation) repo may also be worth checking out. It manages _"the continuous deployment of the Pangeo Cloud Federation JupyterHub Kubernetes clusters"_ and "_contains scripts to automatically redeploy when the image definition or chart parameters are changed"_.  Underneath, it makes us of [hubploy](https://github.com/yuvipanda/hubploy), a _"suite of commandline tools & a python library for continuous deployment of JupyterHub on Kubernetes (with Zero to JupyterHub)_" that comes in two parts: _"a__n image builder that builds images from subpaths of git repositories only when needed, and a helm wrapper that deploys a helm chart when required"_.  
  
On MyBinder (which from [#TJ16](https://github.com/TrackingJupyter/archive/blob/master/TJ16.md) seems to incur about $100 per week for its 50TB of Docker image storage), it seems that users are _"__guaranteed at least 1GB of RAM, with a maximum of 2GB"_; there's also currently a cap of 100 current instances running from the same repository _\[the __c.BinderHub.per\_repo\_quota config parameter, presumably? \[[docs](https://buildmedia.readthedocs.org/media/pdf/binderhub/latest/binderhub.pdf)\] —Ed.__\]_, with kernels shutting down _"after __more than 10 minutes of inactivity__"_. In passing, here's a[handy tip](https://discourse.jupyter.org/t/would-a-the-littlest-binder-be-useful/1041/10) (and [issue](https://github.com/jupyterhub/binderhub/issues/848) until it makes the docs) for banning / excluding repositories launched from Binderhub.  
  
Elsewhere, folk at the Turing Institute _"need to figure out the billing strategy"_ before they make their Binderhub available _\[so much for a federated "open as in freely available" Binder community?! Where does the toll booth go on the [latest sketch](https://discourse.jupyter.org/t/hub-illustrations/1211) they commissioned, I wonder?!;-) Hopefully, they also add a free Binder to the community too... But yes, yes, I know: sustainability...—Ed\]_, whilst for Edina's _Noteable_ hosted notebook service, it seems that billing will incorporate development costs for new features along with coverage of infrastructure costs.  
  
Back in open Binder land, the [Devito](https://www.devitoproject.org/) Symbolic Finite Difference Computation code generation framework has just launched it's own Binderhub, the excellently named [devito.rocks](http://devito.rocks/).  
  
Some services I've recently spotted operating Jupyterhubs in the wild _\[these will typically be for registered users only. —Ed.\]_: 

*   [Chameleon](https://www.chameleoncloud.org/), a configurable experimental environment for large-scale cloud research \[[hub](https://jupyter.chameleoncloud.org/hub/login)\];
*   National Center for Supercomputing Applications ([NCSA](http://www.ncsa.illinois.edu/)), Illinois \[[hub](https://browndog.ncsa.illinois.edu/jupyter/hub/login)\];
*   [Bioinformatics Facility](http://facility.bioinformatics.ucr.edu/) at UCR \[[hub](https://jupyter.bioinfo.ucr.edu/hub/login)\];
*   George Washington University Libraries and Academic Innovation ([GWLAI](https://lai.gwu.edu/)) \[[hub](http://jupyter.lai.gwu.edu/hub/login)\];
*   [College of Science](https://science.iit.edu/computer-science) at the Illinois Institute of Technology \[[hub](https://braeburn.cs.iit.edu/jupyter/hub/login)\].

You get the idea... Just look for a crib. A handy one to search on is: _[inurl:hub/login jupyter](https://www.google.com/search?q=inurl:hub/login+jupyter) \[you may be asked if you're a robot; Google doesn't like people using advanced search limited searches...—Ed.\]_. Adding _site:ac.uk_ to the mix is not encouraging.  
  
By the by, here's another way I spotted of discovering institutional Jupyter services: [outage status alerts](https://status.ucsd.edu/incidents/8lqqm54g78c2?u=p6fgznbc0yy8).  
  
Also institutionally, NERSC, the (US) National Energy Research Scientific Computing Center, looks like they've just started up a repo to track project ideas around their [Jupyter Superfacility](https://github.com/NERSC/Jupyter-Superfacility) project _\[I'm not sure if this is distinct to their current [Jupyter support](https://docs.nersc.gov/connect/jupyter/)...?—Ed.\]._

Imaging, the Second...
----------------------

For a discussion of 3D rendering issues, with notebook examples rendered using _ipyvolume_ ([#TJ6](https://github.com/TrackingJupyter/archive/blob/master/TJ6.md#jupyter-goes-3d)) see this blog post on [Multivolume rendering in Jupyter with ipyvolume: cross-language 3d visualization](https://towardsdatascience.com/multivolume-rendering-in-jupyter-with-ipyvolume-cross-language-3d-visualization-64389047634a). The post also mentioned that _"a C++ binding to the frontend code of ipyvolume, [xvolume](https://github.com/QuantStack/xvolume) is under development" \[though there don't seem to be many recent commits to that project, so maybe is stalled? Or completed?! —Ed.\]_ as well as introducing the [glue-jupyter](https://github.com/glue-viz/glue-jupyter) extension. This provides an _ipvolume_ / notebook based user interface for [Glue](http://docs.glueviz.org/en/stable/index.html), a Python library _"for exploring relationships within and among datasets"_ that has to date made use of a Qt based front-end. Binderised demo notebooks including visualising astronomical FITS data and aircraft flight records.  
  
[yt](https://yt-project.org/) is another visualisation framework for analyzing and visualizing volumetric data that _"__has been applied in domains such as astrophysics, seismology, nuclear engineering, molecular dynamics, and oceanography"_. Notebook support comes in the form of [widgyts](https://github.com/data-exp-lab/widgyts), _"\[a\] fully client-side pan-and-zoom widget, using WebAssembly, for variable mesh datasets from yt"_. See this related [presentation](https://utokorea.blogspot.com/2019/04/pydata-pydata-ann-arbor-madicken-munk.html). It's not Binderised — yet— but [looks like](https://github.com/data-exp-lab/widgyts/issues/36) it will be soon... _\[The data file used in the example notebook was missing, but I found it via another interesting [post](http://www.astroblend.com/tutorials/tutorial_simpleRender.html) that manipulated the same file using Blender... To run the demo also required pip installing h5py. —Ed.\]_  
  
For something more specifically molecular, the [3dmol.js](https://3dmol.csb.pitt.edu/) _"__object-oriented JavaScript library for visualizing molecular data"_ is exposed variously in Jupyter notebooks using the deprecated(?) [py3Dmol](https://github.com/avirshup/py3dmol), or [NBMolViz](https://github.com/Autodesk/notebook-molecular-visualization), the _Molecular Design Toolkit_ that _"provides visualization and interactivity for 3D Molecular Structures"_.   
 

Notebook Storage
----------------

In the beginning, was a notebook, Then there were several notebooks, Then there were notebooks all over the place. If you're managing a shared collection of notebooks, the problem only escalates. So what solutions are there to help manage increasingly large notebook collections, if you work across multiple machines or if you're part of a distributed team?

If it's just file syncing you're after, the [jupyterlab-google-drive](https://github.com/jupyterlab/jupyterlab-google-drive) extension would be one place to start. It looks as if someone was working on a [jupyterlab-dropbox-plugin](https://github.com/sunyi000/jupyterlab-dropbox-plugin) too _\[but I have to admit, I haven't tried either of those extensions... —Ed.\]_  
  
If you need enterprise level, cloud based storage, the _nteract_\-verse, [commuter](https://github.com/nteract/commuter)_"reads notebooks from a local directory or Amazon S3, has a directory explorer to find notebooks, and provides a jupyter compatible version of the contents API"_. Interestingly, the demo is served using _glitch_. _\[I have to admit, I can't get my head round how nteract universe tools are supposed to work together either... So that's nteract and JupyterLab that have both left me behind!—Ed.\]_  
  
The [nteract bookstore](https://bookstore.readthedocs.io/en/latest/) \[[repo](https://github.com/nteract/bookstore)\] steps things up a level _\[erm, I think...?!—Ed.\]_ by _"provid\[ing\] tooling and workflow recommendations for storing, scheduling, and publishing notebooks"_. It also helps out with versioning, as _"\[e\]very save of a notebook creates an immutable copy of the notebook on object storage \[currently versioned S3 buckets\]"_. _\[I have no idea how this works, or where it could fit in workflow terms compared to commuter. I needz picturez... It would also be useful to put together a comparison with something like nbgallery.—Ed.\]_  
  
One crucial piece of the jigsaw that makes "what goes where" management possible is the Jupyter notebook [_ContentsManager_ class](https://jupyter-notebook.readthedocs.io/en/stable/extending/contents.html). This_ "defines an abstract API for translating \[file creation, opening, renaming, and deletion\] interactions into operations on a particular storage medium. The default implementation, FileContentsManager, uses the local filesystem of the server for storage and straightforwardly serializes notebooks into JSON. Users can override these behaviors by supplying custom subclasses of ContentsManager"_. For example, Quantopian's [pgcontents](https://github.com/quantopian/pgcontents) offers a _"PostgreSQL backed ContentsManager"_, and [Jupyter S3](https://github.com/uktrade/jupyters3)_\[on the UK Department for International Trade Github account...—Ed.\]_ provides a _"Jupyter Notebook Contents Manager for AWS S3"_. Alternatively, [hdfscontents](https://github.com/alshishtawy/hdfscontents) implements a _"contents manager for Jupyter that stores files in Hadoop File System (HDFS)"_ and [s3contents](https://github.com/danielfrg/s3contents)_"an S3 and GCS backed ContentsManager"_. For the [_girder_](https://girder.readthedocs.io/en/stable/) open source web-based data management platform, there's [girder\_jupyter](https://github.com/girder/girder_jupyter).   
  
_\[By the by, the ContentsManager class is also co-opted by Jupytext to support the dualling of notebook saves into formats other than the ipynb notebook JSON format.—Ed.\]_

Imaging, the Third...
---------------------

When it comes to imaging, there seems to be quite a lot out there because different topic areas often seem to develop their own tooling. The new to me [Image Data Resource](https://idr.openmicroscopy.org/about/) (IDR) is an _"online, public data repository seeks to store, integrate and serve image datasets from published scientific studies"_. There's a set of [Jupyter notebooks](https://github.com/IDR/idr-notebooks) showing how to work with it if you fancy a mooch around... _"IDR datasets are annotated with author-supplied metadata (e.g., annotations, defined regions, feature vectors and ontological annotations) that are all stored and available for browsing. All metadata are also available through the OMERO API."_  
  
If you want something more specific, and nanoscale materials imaging data does it for you, [pycroscopy](https://github.com/pycroscopy/pycroscopy) is an HDF5 image handling Python package _"for image processing and scientific analysis of imaging modalities such as multi-frequency scanning probe microscopy, scanning tunneling spectroscopy, x-ray diffraction microscopy, and transmission electron microscopy"_.  
  
For single-cell bacterial fluorescence microscopy data analysis _\[of course...—Ed.\]_, it looks like [ColiCoords](https://github.com/Jhsmit/ColiCoords) offers a place to start in the form of _"an open, well documented platform where users can easily share data through compact HDF5 files and analysis pipelines in the form of Jupyter notebooks"_.  
  
_\[HDF5 seems to be one to watch... there may well be scope for tools crossing subject divides...—Ed.\]_  
  
If visualising 3D earth sciences data is more your thing, [OpenGeoVis/omfvista](https://github.com/OpenGeoVis/omfvista) provides a VTK interface for the [Open Mining Format](https://omf.readthedocs.io/en/latest/) package (_omf_), _"a standard for mining data backed by the Global Mining Guidelines Group"_, apparently...  
  
Digging deeper _\[doh! —Ed.\]_ the [empymod](https://empymod.github.io/) framework provides geophysicists with a multigrid solver for 3D electromagnetic diffusion with tri-axial electrical anisotropy _\[erm....?! —Ed.\]_. I have no idea what any of that means, but the [notebook examples](https://github.com/empymod/emg3d-examples) look interesting. _\[They don't seem to be Binderised at the moment, though..?—Ed.\]_  
  
If you prefer things just above the ground, the [plantcv](https://github.com/danforthcenter/plantcv) folks have produced a set of [Binderised notebook docs](https://github.com/danforthcenter/plantcv-binder) showing how to get started with plant image analysis using OpenCV.  
 

Notebook Library Shelves
------------------------

As well as routing the storage of notebooks on backend, as mentioned above, there's also emerging practice around the everyday process of managing and sharing notebooks.

For example, this [collection](https://github.com/ibressler/jupyter-git-scripts) of batch scripts for helping version control Jupyter notebooks on Windows is interesting. A JupyterLab extension for GIT allows to commit changes on a notebook directly from JupyterLab, with no command-line interaction necessary. The scripts are intended to be run by restricted users typically found in corporate computing environments and follows the following steps:

*   presents a dialog asking the user for an empty project folder, allows a new folder to be created;
*   initializes GIT in that project folder, using user name and email provided by Windows via Active Directory;
*   sets up GIT with Jupyter notebook filtering (_nbstripout_) in that folder;
*   adds a copy of the notebook template;
*   adds configured GIT submodules;
*   expects a config file.

For sharing notebooks, [Jovian](https://www.jvn.io/) (jvn.io) is a site that lets you _"upload Jupyter notebooks and generate shareable links with a single command within Jupyter"_. The incantation you need to summon up comes in the form of [jovian-py](https://github.com/swiftace-ai/jovian-py).  
  
For running a notebook someone has shared with you _without_ the need to run your own notebook server, I made a minor tweak to the simple [nbpreview](https://github.com/jsvine/nbpreview) service that lets you upload and preview a notebook using [notebookjs](https://github.com/jsvine/notebookjs) so that you can execute the code against a demo Binderhub container using ThebeLab. The fork is [here](https://github.com/ouseful-pr/nbpreview/tree/thebelabify) and a demo is [here](https://ouseful-pr.github.io/nbpreview/); code _changes_ to _notebookjs_ are [here](https://github.com/ouseful-pr/notebookjs/tree/thebelabify). The demo also has a button to _download_ the code from the previewed notebook, in case you change it... _\[This is a work in progress, and is just a working skecth at the moment...—Ed.\]_  
  
If you're running a course that makes use of Jupyter notebooks, your students will need to get hold of the notebook files somehow. If you're storing the files in Github, this "just" requires downloading notebooks from there. But "just" can unpack a long way. And wouldn't it be neater if you could integrate notebook retrieval within a Jupyter environment?  
  
[jupyterhub/nbgitpuller](https://github.com/jupyterhub/nbgitpuller) is a Jupyter ServerExtension that allows you to sync a git repository, with automatic conflict resolution, in a one-way direction _from_ the repo _to_ a local path. This is handy because it lets you distribution materials to users from Github (or another Git service) without the user having to understand git. To create the required URL, there's also this handy [form generator](https://jupyterhub.github.io/nbgitpuller/link). _\[See also this [ongoing discussion](https://github.com/jupyterhub/nbgitpuller/issues/53) regarding pulling from private repositories...—Ed.\]_  
  
As Chris Holdgraf observed in the Jupyter discourse forum, if you have a Binderised repository that installs _nbgitpuller_, you can use it to pull notebooks from another repository into one launched from MyBinder. The trick? Use URLs of the form:  
  
[https://mybinder.org/v2/gh/BASE\_USER/BASE\_REPO/BASEBOXBRANCH/?urlpath=git-pull?repo=https://github.com/USER/REPO%26amp%3Bbranch=BRANCH](https://mybinder.org/v2/gh/ouseful-demos/binder-base-boxes/BASEBOXBRANCH/?urlpath=git-pull?repo=https://github.com/USER/REPO%26amp%3Bbranch=BRANCH)  
  
_\[As a riff around this, I've started creating some topic specific "Binder base boxes" in the branches of [this repo](https://github.com/ouseful-demos/binder-base-boxes). For example, [this link](https://mybinder.org/v2/gh/ouseful-testing/binder-graphviz/master/?urlpath=git-pull?repo=https://github.com/hchasestevens/show_ast) launches a "graphviz base box" and opens a noteboof from another repo into it, though you'll need to tweak the print statements to Py3 print() form for it to work!.—Ed.\]_  
  
One advantage of this approach is that you can create a MyBinder environment with a complex build sequence, build it once, then load notebooks you're changing regularly into it from another repo _without having to go through the container rebuild cycle after each change to the notebook repo._  
  
If you only want to retrieve a few specified notebooks from the repository, though, you'll need a different approach. Which is where the next tool may come in handy...  
  
[nblibrarian](https://github.com/lheagy/nblibrarian) provides a suite of _"tools for maintaining a library of Jupyter notebooks that are sourced from a 'warehouse' of notebooks (another github repository)"._ As @lindsey\_jh puts it: _"nblibrarian tries to separate maintenance from content delivery"_. And also via Twitter, @mdpacer provides me with an example: [geoscixyz/geosci-labs](https://github.com/geoscixyz/geosci-labs) is a large collection of _"notebook-apps for concepts in applied geophysics"_; [geoscixyz/geosci-course](https://github.com/geoscixyz/geosci-course) is a small repo containing example_nblibrarian_ config files for retrieving a listed subset of notebooks from the _geosci-labs_ repo._nblibrarian_ configurations can be used to sample the contents of the full _geosci-labs_ repo to produce courses, or more focussed repos, such as [geoscixyz/em-apps](http://https://github.com/geoscixyz/em-apps).  
  
So how does it work? A _.library-config.yml_ file specifies details of the source repository and identifies environment configuration files contained within it; a _.jupyter-include_ file, which follows the same syntax as a [.gitignore](https://git-scm.com/docs/gitignore) file, describes which notebooks you would like included in your library. Theassumption is that notebooks will be re-used _as-is_ from specified repo. Running _nblibrarian_ from the command line will then download the files you specified from the identified repo; by default, it will not overwrite your current notebooks but can force overwrites if required. If you want to modify or update your library, you can alter the _.jupyter-include_ file and re-run _nblibrarian_.  
  
At a more general, not strictly Jupyter, level, the Python [repo2data](https://github.com/simexp/repo2data) package, an _"automatic data fetcher from the web_", looks like it could be a handy tool for grabbing and decompressing data sets.

And Finally...
--------------

One of my gripes about JupyterLab is that the interface is too complicated for novices, particularly ones who aren't interested in becoming, (and shouldn't be expected to become), "developers". The notebook interface is a completely different offering, but could that be simplified further too? The _nteract_ app offers quite a cut down UI compared to the default browser based notebook, but how about the browser experience? Yuvi Panda's been exploring a variant of his "littlest" meme in exactly this context: [simplest-notebook](https://github.com/yuvipanda/simplest-notebook), _"a Jupyter Notebook frontend with simplest possible UI"_.  
​

* * *

Disclaimer: this newsletter is produced independently of the official Jupyter project.

_All errors are down to the editor... Oops.. If I make any that I later become aware of, or I'm informed of, I'll announce them in the first possible issue thereafter. If it's really bad, I'll do a Stop Press/emergency issue._

If you have any Jupyter related news items or notebooks you'd like to be considered for inclusion in the newsletter, or experiences of using any of the technologies described in this newsletter that you'd like to share, please email them along to: tony.hirst@open.ac.uk
