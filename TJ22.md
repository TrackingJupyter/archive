Welcome to this twenty-second edition of the _Tracking Jupyter_ newsletter (#TJ22).  
  
I've no idea when the next one will be, and this is little more than an overly opinionated, rag-tag interim post... _\[This side project may well have run its course... —Ed.\]_

News and Observations
---------------------

IPython is [now out](https://discourse.jupyter.org/t/release-of-ipython-7-7/1775) at v7.7, and plotly.py is at [v4](https://medium.com/plotly/plotly-py-4-0-is-here-offline-only-express-first-displayable-anywhere-fc444e5659ee), repo2docker is [up to](https://repo2docker.readthedocs.io/en/latest/changelog.html#version-0-10-0) v.0.10, and nbconvert is [out at](https://discourse.jupyter.org/t/nbconvert-5-6-0-release/1867) v5.6.0.  
  
If you fancy a job working at JP Morgan on a JupyterHub / JupyterLab / Voila infrastructure stack, here's [an informal ad](https://discourse.jupyter.org/t/jupyterlab-voila-development-nyc-london-jp-morgan/1893). Quansight are also [looking for](https://discourse.jupyter.org/t/quansight-hiring-remote-jupyterlab-developer/1894) someone to work one JupyterLab extension development.  
  
Something I keep meaning to try out: [running Jupyter in a Chromebook](https://alex.miller.im/posts/data-science-chromebook-pixelbook-jupyter-python-r/). _\[I'm not sure what percentage of students have Chrome Books, and I suspect many of those that do have cheaper specced ones, but this is an approach to keep an eye on, I think...—Ed.\]_  
  
If you're looking to run JupyterHub on a Hadoop cluster, [this](https://jupyterhub-on-hadoop.readthedocs.io/en/latest/) may help... For something even more opinionated, try this[ Zero-to-JupyterHub with Kubernetes using a very specific tech stack](https://github.com/parente/z2jh-aws): built from a Mac _\[so you need Homebrew for installing client tools for starters, plus Make to, erm, make things easy...—Ed.\]_, it builds on Terraform, AWS Elastic Kubernetes Service (EKS) and Elastic Container Registry (ECR), Helm, Cloudflare and Let's Encrypt. If it's CUDA support you're after, the [source{d}](https://sourced.tech/) data platform infrastructure bods have [shared](https://github.com/src-d/infrastructure-dockerfiles/blob/master/ml-infra-jh-cuda-python/Dockerfile) [their](https://github.com/src-d/infrastructure-dockerfiles/tree/master/ml-infra-cuda-python) [Dockerfiles](https://github.com/src-d/infrastructure-dockerfiles/tree/master/ml-infra-base-python) for getting your GPU support JupyterHub platform up and running. Whilst over at the Turing Institute, there's a handy Zero-to-Binderhub [tutorial guide](https://github.com/alan-turing-institute/the-turing-way/blob/master/workshops/build-a-binderhub/workshop-presentations/zero-to-binderhub.md) for getting into the Binder thing... _\[I really need to do some gardening on my deployment guide wiki page... —Ed.\]_  
  
Perhaps also of interest the the devops folk, a[post](https://blog.jupyter.org/automating-mybinder-org-dependency-upgrades-in-10-steps-bb5e38542059) from the MyBinder team on the bot they use for automatically updating the versions of BinderHub and repo2docker deployed on mybinder.org. And for lazy devops folk, [jupyter-libcloudspawner](https://github.com/tristanlt/jupyter-libcloudspawner) may be of interest: _"a JupyterHub Spawner that allows JupyterHub to launch users notebooks inside cloud instance. \[B\]ased on Apache Libcloud, \[it\] provides an abstraction API for \[several\] cloud providers, including OpenStack, Google Cloud Engine, Amazon AWS and CloudStack"_.  
  
For the hardware hackers, PYNQ is _"an open-source project from Xilinx that makes it easy to design embedded systems with Zynq Systems on Chips (SoCs)"_. Notebook UIs have been in place for some time to help code Zynq SoCs ([#TJ16](https://github.com/TrackingJupyter/archive/blob/master/TJ16.md#at-the-heart-of-it-all)), but it seems that JupyterLab [may now be](https://blog.hackster.io/microzed-chronicles-pynq-rfsoc-sdfec-f70b3b232d6) the default UI. If you're into hardware, but of the Raspberry Pi kind, here's a recently [updated](https://github.com/romilly/rpi-docker-tensorflow) Docker container for the Raspberry Pi containing Tensorflow and Jupyter. On the other, if you prefer tinkering with electronics, this [set of notebooks](https://github.com/CapableRobot/notebooks) for Better Electronics with Jupyter Notebooks using Capable Robot products may appeal.  
  
If you want to run notebook code cells at scale on AWS Lambda, the [eigensheep](https://github.com/antimatter15/eigensheep) _\["lamb, duh...", or something... —Ed.\]_ lets you do just that. _\[In passing, [this scraggy demo](https://gist.github.com/psychemedia/ca2d41ea5fcf37d1c6473d4384742021) of my own lets you launch a MyBinder kernel and run code on it from your own Python notebook. I had wondered about making magic from it... But how would I pass eg a dataframe object back?  —Ed.\]_  
  
That also reminds me of this earlier [proof of concept](https://github.com/murhum1/remote-notebook-cells) demo for executing Jupyter notebook cells remotely, such as running a single cell on a GPU machine. The example defines a _%%GPUCell_ cell magic that attempts to _"save as much as possible of the notebook's state, imports the state and run the GPU cell in its own python process, saves the remote state and then import it back into the original notebook"_. _\[I haven't tried it, so you do have to... —Ed.\]_. If you do start running things on your own GPU, there are a couple of JupyterLab extensions that might be handy for reviewing GPU performance: [jupyterlab-nvdashboard](https://github.com/jacobtomlinson/jupyterlab-nvdashboard) and this new looking one, [jupyterlab-gpu-stats](https://github.com/tlkh/jupyterlab-gpu-stats).  
  
Adding to some of the ways of keeping secrets described in [#TJ16](https://github.com/TrackingJupyter/archive/blob/master/TJ16.md#keeping-notebook-secrets), this [keyring](https://github.com/jaraco/keyring) Python package provides easy access to system keyrings including the macOS _Keychain_, the Freedesktop _Secret Service_, the KDE _KWallet_ and the Windows Credential Locker. Whilst from [#TJ17](https://github.com/TrackingJupyter/archive/blob/master/TJ17.md#training-data-annotation-tagging-extensions), the _Innotater_ extension for tagging training datasets is [now supported](https://github.com/ideonate/jupyter-innotater#3---installation) in JupyterLab as well as notebooks.  
  
On the _pandas'n'notebooks_ front, [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling) _"generates profile reports from a pandas DataFrame"_ and has recently started accelerating through the low v2 point releases, whilst [Jupyter DataTables](https://github.com/CermakM/jupyter-datatables), a Jupyter notebook extension to _"leverage pandas DataFrames by integrating DataTables JS"_ bumped up to v0.3.0, and then some... Perhaps also of note, it seems to make use of the [jupyter-require](https://github.com/CermakM/jupyter-require) extension for managing the necessary JavaScript and CSS libraries. I also note that this package — [bamboolib](https://bamboolib.com/) — is being teased at the moment. From the video, it seems to blend Jupyter DataTables with OpenRefine, all over _pandas_ and in a notebook context...  
  
For richer markdown editing, this interestingly named [jupyter-scribe](https://github.com/jupytercalpoly/jupyterlab-richtext-mode) JupyterLab extension _"transforms Markdown cells into rich-text-editing cells, powered by ProseMirror"_. There's a Binderised demo if you want to give it a spin...  
  
For a long time now, I've been wondering how Jupyter mediated remote execution of code embedded in online documents is going to affect documentation. Javascript packages like _ThebeLab_ and _Juniper.js_ let you enliven and run code embedded in webpages using remotely launched MyBinder kernels, but a lot of docs are still written using Sphinx. [This post](https://tomaugspurger.github.io/pandas-binder.html) describes how [sphinxcontrib-jupyter](https://sphinxcontrib-jupyter.readthedocs.io/en/latest/) was use to turn the ReST files _\[that is, ReStructured Text files...—Ed.\]_ that document the _pandas_ package to Jupyter notebooks running on MyBinder. The repo that works the conversion is [here](https://github.com/pandas-dev/pandas-binder); it shows how to include the original _pandas_ repo as a submodule as well as including code to run the translation for ReST documents to notebooks, and is perhaps a good candidate for being a template repo. _\[I wonder, could CircleCi be used to automate that? It can certainly be used for [schedulng scrapers](https://simonwillison.net/2019/Mar/13/tree-history/)...—Ed.\]_ Also related, [Jupinx](https://jupinx.quantecon.org/) \[[toolkit repo](https://jupinx.quantecon.org/)\], an _"open source tool for converting ReStructuredText source files into a website via Jupyter Notebooks"_. One thing I did wonder, though, was whether this is would all be necessary if Jupytext could convert ._rst _files to notebooks on the fly?  
  
Following on in a similar documentation vein, [_ChipWhisperer_](https://github.com/newaetech/chipwhisperer) is _"an open source toolchain dedicated to hardware security research"_ comprising hardware, firmware and software components, with docs handled via notebooks.  
  
In my personal side project doodlings, I've recently started thinking about how I can use [papermill](https://github.com/nteract/papermill) for parameterising notebooks to produce various reports on a theme; [this article](https://pythonawesome.com/a-tool-for-parameterizing-and-analyzing-jupyter-notebooks/) provides a really handy summary of a _papermill_ workflow, showing how to create parameterised notebooks, as well as call them from, and report elements of them back into, other notebooks.  
  
For your viewing pleasure, if you're still not sure what Voila is or how it can help you with your widgetised dashboards, check out this [presentation from SciPy 2019](https://www.youtube.com/watch?v=VtchVpoSdoQ). Voila is supporting an ever increasing range of interactive frameworks, such as the [Vuetify](https://v15.vuetifyjs.com/en/) material design component framework _\[whatever that means?!—Ed.\]_ via [ipyviewtify](https://github.com/mariobuikhuizen/ipyvuetify) and [voila-vuetify](https://github.com/QuantStack/voila-vuetify), so it's properly bedding itself in. Alternatively _\[or perhaps, that's "as well"? —Ed.\]_ there's the _pyviz_[panel](https://github.com/pyviz/panel) package _"for easily composing widgets, plots, tables, and other viewable objects and controls into control panels, apps, and dashboards"_; I _think_ you can use _panel_ apps with Voila, although you probably can't with dashboards created using _plotly.dash_. _\[In other news, I notice that plotly.dash now also works with R as well as Python... —Ed.\]_ For a review of all three, see this review of [Jupyter Dashboarding — some thoughts on Voila, Panel and Dash](https://medium.com/informatics-lab/jupyter-dashboarding-some-thoughts-on-voila-panel-and-dash-b84df9c9482f). Also related, [ipybokeh](https://github.com/pyviz/ipybokeh) provides _"an IPython widget to render and add perform bi-directional communication to Bokeh Models in notebook environments"_.  
  
I'm still in two minds about the new [_handout_](https://github.com/danijar/handout) package, proclaimed as _"\[a\]n alternative to Jupyter notebooks without hidden state that supports any text editor"_. Hack a py file, adding markdown via comments, and use some package commands to output text, variable values, figures, custom HTML, etc, then churn it into an HTML file. (Here are [some examples](https://www.tdt.com/support/python-sdk/offline-analysis-examples/), and the code to [generate them](https://github.com/tdtneuro/handouts).)  Simple, yes; and it doesn't require Jupyter machinery. I guess it does what it does. But I find [my emerging workflow](https://blog.ouseful.info/2019/08/05/exploring-jupytext-creating-simple-python-modules-via-a-notebook-ui/) — install Jupytext, hack a py file _in a notebook UI_, use tagged cells to essentially comment out code from docs loaded as modules, but let me run them when testing from the module doc itself, use autoreload in other documents to load in updates from changed modules — is starting to make my own hamfisted attempts module development under source code / version control a bit easier. As to the hidden state problem, if you get into the habit of restarting a kernel and then "Run all cells above", or use the default  notebook _"fast forward play"_ toolbar button to restart the kernel and run all cells (perhaps using an _exit(-1)_ to halt execution after a given cell), where's the hidden state? As a data scientist in search of sponsorship [noted](https://twitter.com/DocFast/status/1159108776244461568): _"\[t\]he next ten million notebooks will tell about best practices, the first five million were just practice. Software best practices are not notebook best practices"_.  
  
Although it isn't out yet, and it's perhaps unfair for me to trail it as a new item just yet, this [accessibility\_toolbar](https://github.com/uclixnjupyternbaccessibility/jupyter_contrib_nbextensions/tree/master/src/jupyter_contrib_nbextensions/nbextensions/accessibility_toolbar) extension could be interesting... _\[With a new academic year looming, getting accessibility improvements tested and working so they can be used from the off with a new intake of students would surely be a Good Thing, right? —Ed.\]_ If you want to know where Jupyter UIs are failing on the accessibility front, there's a link to an [accessibility audit](https://docs.google.com/document/d/1q_7LiqLX2WGJZ0UHNWDFafw75McZgLp9v4Ifdzn2FYE/edit) doc from this [related thread](https://discourse.jupyter.org/t/accessibility-audit-for-jupyter-notebook/1850) on the Jupyter discourse forums.  
  
Not really Jupyter, but it caught my eye... one for the C++ hackers, [matplotlib-cpp](https://github.com/lava/matplotlib-cpp), _"built to resemble the plotting API used by Matlab and matplotlib"_. If you prefer Fortran, [LFortran](https://docs.lfortran.org/) is _"a modern open-source (BSD licensed) interactive Fortran compiler built on top of LLVM"_ that can be run as a Jupyter kernel. Or perhaps rather more contemporary, here's a [Rust kernel](https://github.com/google/evcxr/blob/master/evcxr_jupyter/README.md).  
  
On the Python kernel front, the alternative Xeus Python kernel was [released](https://github.com/QuantStack/xeus-python) at the v.0.4 level and includes a debugger based on the _\[cross-IDE platform? —Ed.\]_ [Debug Adapter Protocol](https://microsoft.github.io/debug-adapter-protocol/) _\[and I'm guessing that means it should play nicely with the [jupyterlab-debugger](https://github.com/QuantStack/jupyterlab-debugger) extension? —Ed.\]_. I also note that the August 2019 release of Microsoft VS Code [includes](https://devblogs.microsoft.com/python/python-in-visual-studio-code-august-2019-release/) Jupyter notebook cell debugging.  
  
Only slightly bonkers, [this](https://github.com/nat-chan/vim.wasm.ipynb)_"proof-of-concept fork of vim.wasm aims to integrate Jupyter and vim.wasm"_. I fully expect to see all manner of web-assembly apps starting to appear in notebooks, as if by magic... _\[The sharks will soon start jumping...—Ed.\] _If you prefer emacs, [emacs-jupyter](https://github.com/dzop/emacs-jupyter) provides an API for hooking up that desktop editor to Jupyter kernels.  
  
I haven't really paid much attention to Amazon's DeepRacer, but [this post](https://codelikeamother.uk/using-jupyter-notebook-for-analysing-deepracer-s-logs) on using Jupyter Notebooks for analysing DeepRacer logs made me wonder if I could use that data for sketching out motorsport related visualisations? On the other hand, if you want to play with _real_ car data, Lyft shared a [load](https://level5.lyft.com/dataset/) of theirs. Complementing simulated race data, [this post](https://technology.amis.nl/2019/08/14/analyzing-the-2019-tour-de-france-in-depth-using-strava-performance-data-from-race-riders/) describes how to get hold of personal activity tracking data from cyclists competing in le Tour _\[that is, the Tour de France... For the non-sports-wheel fans, it's a bike race... —Ed.\]_ and have a play with it yourself...  
  
It may have been there for some time, but I notice that CoCalc seems to bundle _nbgrader_, with [support](https://doc.cocalc.com/teaching-course-management.html) for distributing and collecting assignments to students associated with a particular course.  
  
The Data Science and Engineering Society keep doing this, announcing repos for launching databases in MyBinder contexts _and then not doing that_, instead providing a set of notebooks for you to run to install and fire up the data base yourself. For example, [here's one](https://github.com/thedatasociety/binderhub-grafana) that makes just such a claim to _"launch Grafana with InfluxDB (timeseries database) and Telegraf (metrics collector)"_. _\[I stumbled across another such example earlier today making a similarly styled claim to be a Binderised neo4j repo, so I then felt as if I had to spend a  quick coffee break [actually Binderising it](https://github.com/psychemedia/binder-neo4j)... —Ed.\]_ On the other hand, their [laboratory for learning Hadoop](https://github.com/thedatasociety/lab-hadoop) _does_ seem to Binderise a Hadoop set-up for the lab..[.](https://www.youtube.com/watch?v=fr8GMC_NXlU&t=112)  
  
Something I've started noticing a lot recently is the use of notebooks in "land" related activities. For example, [these notebooks](http://https://github.com/martibosch/pylandstats-notebooks) on _analysing landscapes using computational landscape metrics_, or NASA's [Aria](https://aria.jpl.nasa.gov/) project — _Advanced Rapid Imaging and Analysis (ARIA) Project for Natural Hazard_s — which has a wide range of [tools](https://github.com/aria-tools/ARIA-tools) for working with related geo products, and for which the [docs](https://github.com/aria-tools/ARIA-tools-docs) are provided via notebooks. _\[This message is getting to be the same old, same old, isn't it?! —Ed.\]_  
  
In R land, _\[which I know Ive been neglecting in Tracking Jupyter...—Ed.\]_, this R package — [holepunch](https://karthik.github.io/holepunch/) — looks interesting: _"read the contents of your R project on GitHub, create a DESCRIPTION file with all dependencies, write a Dockerfile, add a badge to your README, and build a Docker image, click the badge, be dropped into a free, live, RStudio server"_. Sounds a lot like MyBinder, doesn't it? And that's exactly what it is... or at least, the holepunch packages generates what you need to Binderise your R project repo, and then it plays out as normal... In passing, I also note the R/knitr [_spin_](https://deanattali.com/2015/03/24/knitrs-best-hidden-gem-spin/) package with its ability to convert R docs to Rmd ones. _\[[Apparently](https://twitter.com/marcwouts/status/1161610184579416065), the spin markdown format "was an inspiring example when elaborat\[ing\] the cross-language 'light' format for Jupyter notebooks as scripts \[in Jupytext\]"...—Ed.\]_ Deeper in the R context, I also note [ggtext](https://github.com/clauswilke/ggtext), that lets you add markdown to _ggplot_ charts.  
  
In JupyterLab extension land, the Data Explorer implementing [jupyterlab/dataregistry-extension](https://github.com/jupyterlab/jupyterlab-data-explorer) is officially out . Meanwhile, this handy looking [jupyterlab-pkginstaller](https://github.com/jupytercalpoly/jupyterlab-pkginstaller) provides _"a JupyterLab UI extension that installs the packages you need (via pip) for your active kernel"_. _\[I really need to spend some time having a play, and getting my head round, this...—Ed.\]_  
  
In passing, I notice one wag on Twitter recently [observing](https://twitter.com/nanxstats/status/1159601318685790209): _"the best of data science bubble in 2019: when someone bundles together an account system + stripped-down GitLab + JupyterLab/RStudio Server and calls it a 'data science platform'"_. That may or may not be true _\[it is...—Ed.\]_, but I have noticed some rather simpler plays which are useful and don't overpromise, like being able to run your Jupyter R notebooks in the cloud using [rnotebook.io](https://rnotebook.io/) or your Julia notebooks using [juliabox.com](https://www.juliabox.com/).  
  
Elsewhere, I spy with my little eye, [dotscience](https://dotscience.com/), a new AI platform offering _"Collaboration Tooling for End-to-End ML Data & Model Management"_ ([docs](https://docs.dotscience.com/))._ \[Hmmm.... I've lost track of how many Jupyter running AI platform accounts I've have (and could have) signed up for... This competes with Comet.ml, among others, right? —Ed.\]_  
  
Perhaps useful on the advocacy front, the _Ten Simple Rules for Writing and Sharing Computational Analyses in Jupyter Notebooks _paper ([#TJ3](https://github.com/TrackingJupyter/archive/blob/master/TJ3.md#preprints)_\[yes, you read that right: 3; three,..—Ed.\]_) is now [officially out](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007007) and citeable as: _Rule A, Birmingham A, Zuniga C, Altintas I, Huang S-C, Knight R, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLoS Comput Biol 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007_.  
  
Complementing that article, this [recent online PhD disseration](http://dissertation.jeriwieringa.com/notebooks/notebooks-overview/) on _"Modeling the Religious Culture of Seventh-day Adventism, 1843 - 1920"_ includes a set of notebooks used in the associated research _\[the compsci priesthood have so lost control of coding... No wonder they hate notebooks and everyday/popular Python packages so much... :-) —Ed.\]_.  
  
As someone who quite possibly knows [observes](https://twitter.com/pwang/status/1159885511286317056), _"\[p\]ractically \*everything\* that is part of today's rising star in data science comes from non-CS devs. All written by physicists, engineers, quants... That they found the Python language a beautiful and productive one for expressing their ideas.. that's meta-Pythonic."_  
  
And finally, if you're: a) reading this newsletter, and you've b) read this far into it, you've almost certainly drunk of the Jupyter Kool Aid; but you still maybe need help trying to persuade others that Jupyter's a Good Thing _\[I know I certainly do...—Ed.\]_ So here's another resource that might be useful in putting together a Jupyter advocacy campaign, a [presentation](https://2019.pycon-au.org/talks/building-an-interactive-training-environment-using-jupyterhub) from PyCon (Australia) 2019 on _Building an interactive training environment using JupyterHub_.  
 

From the Twitterz
-----------------

I don't generally do memes, but _"Jupyter Hell"_ could be a really handy one for surfacing usability and workflow issues. For example, a computational social science PhD [considers it to be](https://twitter.com/generativist/status/1158587272633077760) _"the panic between the time you press ii and when the kernel finally interrupts following your fuck up"_ whilst a post-nanopunk goblin cyborg [thinks of it](https://twitter.com/unless_if/status/1158589144181948416) in terms of _"having your teammates all use the same notebook server and directory, getting 'file changed on disk. Overwrite?' messages, and having file names indexed by people's last names"_.  
  
In a related _"what's wrong with Jupyter?"_ vein, this oft repeated [lament](https://twitter.com/contefranz/status/1158451582767443969) from an Assistant Professor — _"\[w\]hat I personally miss the most when switching from R to Python is a consistent framework to draft professional docs. Jupyter is just ok"_ — raises a legitimate concern, I think, whereas [sentiments](https://twitter.com/m_saharia/status/1158642553928978432) of the form _"I have come to dislike Jupyter notebooks, despite using it on a daily basis. No realistic way of source control"_ from a NASA researcher are perhaps not picking up on contemporary workflows using things like Jupytext or VS Code, the latter of which has pushed things on from earlier Atom Hydrogen based workflows.  
 

That's It For This Edition..
----------------------------

_\[No thematic sections... I ran out of time... —Ed.\]_  
 

* * *

Disclaimer: this newsletter is produced independently of the official Jupyter project.

_All errors are down to the editor... Oops.. If I make any that I later become aware of, or I'm informed of, I'll announce them in the first possible issue thereafter. If it's really bad, I'll do a Stop Press/emergency issue._

If you have any Jupyter related news items or notebooks you'd like to be considered for inclusion in the newsletter, or experiences of using any of the technologies described in this newsletter that you'd like to share, please email them along to: tony.hirst@open.ac.uk
